     Elucidating the Design Space of Diffusion-Based
                   Generative Models


                     Tero Karras                                Miika Aittala
                       NVIDIA                                     NVIDIA
                 tkarras@nvidia.com                         maittala@nvidia.com

                       Timo Aila                                Samuli Laine
                        NVIDIA                                    NVIDIA
                   taila@nvidia.com                          slaine@nvidia.com



                                              Abstract

         We argue that the theory and practice of diffusion-based generative models are
         currently unnecessarily convoluted and seek to remedy the situation by presenting
         a design space that clearly separates the concrete design choices. This lets us
         identify several changes to both the sampling and training processes, as well as
         preconditioning of the score networks. Together, our improvements yield new
         state-of-the-art FID of 1.79 for CIFAR-10 in a class-conditional setting and 1.97 in
         an unconditional setting, with much faster sampling (35 network evaluations per
         image) than prior designs. To further demonstrate their modular nature, we show
         that our design changes dramatically improve both the efficiency and quality ob-
         tainable with pre-trained score networks from previous work, including improving
         the FID of a previously trained ImageNet-64 model from 2.07 to near-SOTA 1.55,
         and after re-training with our proposed improvements to a new SOTA of 1.36.



1   Introduction

Diffusion-based generative models [46] have emerged as a powerful new framework for neural image
synthesis, in both unconditional [16, 37, 49] and conditional [17, 36, 37, 39, 40, 42, 43, 49] settings,
even surpassing the quality of GANs [13] in certain situations [9]. They are also rapidly finding use
in other domains such as audio [28, 38] and video [19] generation, image segmentation [4, 57] and
language translation [35]. As such, there is great interest in applying these models and improving
them further in terms of image/distribution quality, training cost, and generation speed.
The literature on these models is dense on theory, and derivations of sampling schedule, training
dynamics, noise level parameterization, etc., tend to be based as directly as possible on theoretical
frameworks, which ensures that the models are on a solid theoretical footing. However, this approach
has a danger of obscuring the available design space ‚Äî a proposed model may appear as a tightly
coupled package where no individual component can be modified without breaking the entire system.
As our first contribution, we take a look at the theory behind these models from a practical standpoint,
focusing more on the ‚Äútangible‚Äù objects and algorithms that appear in the training and sampling
phases, and less on the statistical processes from which they might be derived. The goal is to obtain
better insights into how these components are linked together and what degrees of freedom are
available in the design of the overall system. We focus on the broad class of models where a neural
network is used to model the score [22] of a noise level dependent marginal distribution of the training
data corrupted by Gaussian noise. Thus, our work is in the context of denoising score matching [54].


36th Conference on Neural Information Processing Systems (NeurIPS 2022).
œÉ=0 0.2   0.5   1   2    3    5    7   10     20   50       œÉ=0 0.2    0.5   1   2    3    5    7   10     20   50




        (a) Noisy images drawn from p(x; œÉ)                           (b) Ideal denoiser outputs D(x; œÉ)
Figure 1: Denoising score matching on CIFAR-10. (a) Images from the training set corrupted with
varying levels of additive Gaussian noise. High levels of noise lead to oversaturated colors; we
normalize the images for cleaner visualization. (b) Optimal denoising result from minimizing Eq. 2
analytically (see Appendix B.3). With increasing noise level, the result approaches dataset mean.

Our second set of contributions concerns the sampling processes used to synthesize images using
diffusion models. We identify the best-performing time discretization for sampling, apply a higher-
order Runge‚ÄìKutta method for the sampling process, evaluate different sampler schedules, and
analyze the usefulness of stochasticity in the sampling process. The result of these improvements is a
significant drop in the number of sampling steps required during synthesis, and the improved sampler
can be used as a drop-in replacement with several widely used diffusions models [37, 49].
The third set of contributions focuses on the training of the score-modeling neural network. While
we continue to rely on the commonly used network architectures (DDPM [16], NCSN [48]), we
provide the first principled analysis of the preconditioning of the networks‚Äô inputs, outputs, and loss
functions in a diffusion model setting and derive best practices for improving the training dynamics.
We also suggest an improved distribution of noise levels during training, and note that non-leaking
augmentation [25] ‚Äî typically used with GANs ‚Äî is beneficial for diffusion models as well.
Taken together, our contributions enable significant improvements in result quality, e.g., leading to
record FIDs of 1.79 for CIFAR-10 [29] and 1.36 for ImageNet [8] in 64√ó64 resolution. With all key
ingredients of the design space explicitly tabulated, we believe that our approach will allow easier
innovation on the individual components, and thus enable more extensive and targeted exploration of
the design space of diffusion models. Our implementation and pre-trained models are available at
https://github.com/NVlabs/edm

2   Expressing diffusion models in a common framework

Let us denote the data distribution by pdata (x), with standard deviation œÉdata , and consider the family
of mollified distributions p(x; œÉ) obtained by adding i.i.d. Gaussian noise of standard deviation œÉ to
the data. For œÉmax  œÉdata , p(x; œÉmax ) is practically indistinguishable from pure Gaussian noise. The
                                                                                  2
idea of diffusion models is to randomly sample a noise image x0 ‚àº N (0, œÉmax         I), and sequentially
denoise it into images xi with noise levels œÉ0 = œÉmax > œÉ1 > ¬∑ ¬∑ ¬∑ > œÉN = 0 so that at each noise
level xi ‚àº p(xi ; œÉi ). The endpoint xN of this process is thus distributed according to the data.
Song et al. [49] present a stochastic differential equation (SDE) that maintains the desired distribution
p as sample x evolves over time. This allows the above process to be implemented using a stochastic
solver that both removes and adds noise at each iteration. They also give a corresponding ‚Äúprobability
flow‚Äù ordinary differential equation (ODE) where the only source of randomness is the initial noise
image x0 . Contrary to the usual order of treatment, we begin by examining the ODE, as it offers a
fruitful setting for analyzing sampling trajectories and their discretizations. The insights carry over to
stochastic sampling, which we reintroduce as a generalization in Section 4.

ODE formulation. A probability flow ODE [49] continuously increases or reduces noise level of
the image when moving forward or backward in time, respectively. To specify the ODE, we must first ‚àö
choose a schedule œÉ(t) that defines the desired noise level at time t. For example, setting œÉ(t) ‚àù t
is mathematically natural, as it corresponds to constant-speed heat diffusion [12]. However, we will
show in Section 3 that the choice of schedule has major practical implications and should not be
made on the basis of theoretical convenience.
                                                                                                      
The defining characteristic of the probability flow ODE is that evolving a sample xa ‚àº p xa ; œÉ(ta )
from time ta to tb (either forward or backward in time) yields a sample xb ‚àº p xb ; œÉ(tb ) . Following
previous work [49], this requirement is satisfied (see Appendix B.1 and B.2) by
                                                                   
                                dx = ‚àíœÉÃá(t) œÉ(t) ‚àáx log p x; œÉ(t) dt,                              (1)


                                                        2
Table 1: Specific design choices employed by different model families. N is the number of ODE
solver iterations that we wish to execute during sampling. The corresponding sequence of time
steps is {t0 , t1 , . . . , tN }, where tN = 0. If the model was originally trained for specific choices
of N and {ti }, the originals are denoted by M and {u      j }, respectively. The denoiser is defined as
DŒ∏ (x; œÉ) = cskip (œÉ)x + cout (œÉ)FŒ∏ cin (œÉ)x; cnoise (œÉ) ; FŒ∏ represents the raw neural network layers.
                         VP [49]                 VE [49]                     iDDPM [37] + DDIM [47]              Ours (‚ÄúEDM‚Äù)
Sampling (Section 3)
ODE solver               Euler                   Euler                       Euler                               2nd order Heun
                                                                        i                                                1
                                i                 2    2     2
                                                                     N ‚àí1
Time steps       ti<N    1+   N ‚àí1 (s   ‚àí 1)    œÉmax œÉmin /œÉmax             ubj0 + M ‚àí1‚àíj0 i+ 1 c , where           œÉmax œÅ +
                                                                                      N ‚àí1         2                           1     1 œÅ
                                                                                                                       i
                                                                                                                     N ‚àí1 (œÉmin ‚àíœÉmax )
                                                                                                                               œÅ     œÅ
                                                                             uM = r
                                                                                  0
                                                                                             u2j +1
                                                                             uj‚àí1 =    max(Œ±ÃÑj‚àí1 /Œ±ÃÑj ,C1 ) ‚àí1
                         p    1     2
                                                 ‚àö
Schedule          œÉ(t)      e 2 Œ≤d t +Œ≤min t
                                       ‚àí1            t                       t                                   t
                           p 1 Œ≤ t2 +Œ≤ t
Scaling           s(t)   1    e 2 d    min       1                           1                                   1
Network and preconditioning (Section 5)
Architecture of FŒ∏      DDPM++                   NCSN++                      DDPM                                (any)
                                                                                                                   2
                                                                                                                       / œÉ 2 + œÉdata
                                                                                                                                2
                                                                                                                                     
Skip scaling cskip (œÉ) 1                         1                           1                                   œÉdata
                                                                                                                            p
Output scaling cout (œÉ) ‚àíœÉ                       œÉ                           ‚àíœÉ                                                2 + œÉ2
                                                                                                                 œÉ ¬∑ œÉdata / œÉdata
                         ‚àö                                                     ‚àö                                    p
                                                                                                                              2
Input scaling cin (œÉ) 1/ œÉ 2 + 1                 1                           1/ œÉ 2 + 1                          1/ œÉ 2 + œÉdata
Noise cond. cnoise (œÉ) (M ‚àí 1) œÉ ‚àí1 (œÉ)          ln( 12 œÉ)                   M ‚àí1‚àíarg minj |uj ‚àí œÉ|              1
                                                                                                                 4 ln(œÉ)
Training (Section 5)
Noise distribution       œÉ ‚àí1 (œÉ) ‚àº U(t , 1)    ln(œÉ) ‚àº U(ln(œÉmin ),        œÉ = uj , j ‚àº U{0, M ‚àí1}                                  2
                                                                                                                 ln(œÉ) ‚àº N (Pmean , Pstd )
                                                           ln(œÉmax ))
                         1/œÉ 2                   1/œÉ 2                       1/œÉ 2                                œÉ +œÉdata /(œÉ ¬∑ œÉdata )2
                                                                                                                    2   2
                                                                                                                          
Loss weighting Œª(œÉ)                                                                   (note: ‚àó )
Parameters               Œ≤d = 19.9, Œ≤min = 0.1   œÉmin = 0.02                 Œ±ÃÑj = sin2 ( œÄ2 M (Cj2 +1) )        œÉmin = 0.002, œÉmax = 80
                         s = 10‚àí3 , t = 10‚àí5   œÉmax = 100                  C1 = 0.001, C2 = 0.008              œÉdata = 0.5, œÅ = 7
                         M = 1000                                            M = 1000, j0 = 8‚Ä†                   Pmean = ‚àí1.2, Pstd = 1.2
    ‚àó                                                    ‚Ä†
        iDDPM also employs a second loss term Lvlb           In our tests, j0 = 8 yielded better FID than j0 = 0 used by iDDPM



where the dot denotes a time derivative. ‚àáx log p(x; œÉ) is the score function [22], a vector field that
points towards higher density of data at a given noise level. Intuitively, an infinitesimal forward step
of this ODE nudges the sample away from the data, at a rate that depends on the change in noise level.
Equivalently, a backward step nudges the sample towards the data distribution.

Denoising score matching. The score function has the remarkable property that it does not depend
on the generally intractable normalization constant of the underlying density function p(x; œÉ) [22],
and thus can be much easier to evaluate. Specifically, if D(x; œÉ) is a denoiser function that minimizes
the expected L2 denoising error for samples drawn from pdata separately for every œÉ, i.e.,
   Ey‚àºpdata En‚àºN (0,œÉ2 I) kD(y + n; œÉ) ‚àí yk22 , then ‚àáx log p(x; œÉ) = D(x; œÉ) ‚àí x /œÉ 2 , (2, 3)
                                                                                          

where y is a training image and n is noise. In this light, the score function isolates the noise
component from the signal in x, and Eq. 1 amplifies (or diminishes) it over time. Figure 1 illustrates
the behavior of ideal D in practice. The key observation in diffusion models is that D(x; œÉ) can be
implemented as a neural network DŒ∏ (x; œÉ) trained according to Eq. 2. Note that DŒ∏ may include
additional pre- and post-processing steps, such as scaling x to an appropriate dynamic range; we will
return to such preconditioning in Section 5.

Time-dependent signal scaling. Some methods (see Appendix C.1) introduce an additional scale
schedule s(t) and consider x = s(t)xÃÇ to be a scaled version of the original, non-scaled variable xÃÇ.
This changes the time-dependent probability density, and consequently also the ODE solution
trajectories. The resulting ODE is a generalization of Eq. 1:
                                                                            
                             sÃá(t)                                  x
                    dx =           x ‚àí s(t)2 œÉÃá(t) œÉ(t) ‚àáx log p        ; œÉ(t)   dt.             (4)
                             s(t)                                  s(t)
Note that we explicitly undo the scaling of x when evaluating the score function to keep the definition
of p(x; œÉ) independent of s(t).

Solution by discretization. The ODE to be solved is obtained by substituting Eq. 3 into Eq. 4 to
define the point-wise gradient, and the solution can be found by numerical integration, i.e., taking


                                                                  3
FID                                          FID                                          FID
200                                          500                                           20                         Original sampler
                                                                                                                      Our reimplementation
100                                          200
                                                                                                                      + Heun & our {ti }
 50                                          100                                              10                      + Our œÉ(t) & s(t)
                                              50
 20                                                                                                                   Black-box RK45
                                                 20                                            5
 10
                                                 10
  5                                                                                            3
  3                                               5
  2           35                                  3       27                                                       79
                                                  2                                            2
NFE=8   16   32    64   128   256   512   1024        8    32   128       512   2048   8192        8   16   32   64   128   256    512       1024

    (a) Uncond. CIFAR-10, VP ODE                 (b) Uncond. CIFAR-10, VE ODE (c) Class-cond. ImageNet-64, DDIM
Figure 2: Comparison of deterministic sampling methods using three pre-trained models. For each
curve, the dot indicates the lowest NFE whose FID is within 3% of the lowest observed FID.

finite steps over discrete time intervals. This requires choosing both the integration scheme (e.g.,
Euler or a variant of Runge‚ÄìKutta), as well as the discrete sampling times {t0 , t1 , . . . , tN }. Many
prior works rely on Euler‚Äôs method, but we show in Section 3 that a 2nd order solver offers a better
computational tradeoff. For brevity, we do not provide a separate pseudocode for Euler‚Äôs method
applied to our ODE here, but it can be extracted from Algorithm 1 by omitting lines 6‚Äì8.

Putting it together. Table 1 presents formulas for reproducing deterministic variants of three
earlier methods in our framework. These methods were chosen because they are widely used and
achieve state-of-the-art performance, but also because they were derived from different theoretical
foundations. Some of our formulas appear quite different from the original papers as indirection
and recursion have been removed; see Appendix C for details. The main purpose of this reframing
is to bring into light all the independent components that often appear tangled together in previous
work. In our framework, there are no implicit dependencies between the components ‚Äî any choices
(within reason) for the individual formulas will, in principle, lead to a functioning model. In other
words, changing one component does not necessitate changes elsewhere in order to, e.g., maintain the
property that the model converges to the data in the limit. In practice, some choices and combinations
will of course work better than others.

3     Improvements to deterministic sampling
Improving the output quality and/or decreasing the computational cost of sampling are common
topics in diffusion model research (e.g., [10, 24, 31, 32, 33, 37, 44, 53, 55, 56, 59]). Our hypothesis
is that the choices related to the sampling process are largely independent of the other components,
such as network architecture and training details. In other words, the training procedure of DŒ∏ should
not dictate œÉ(t), s(t), and {ti }, nor vice versa; from the viewpoint of the sampler, DŒ∏ is simply a
black box [55, 56]. We test this by evaluating different samplers on three pre-trained models, each
representing a different theoretical framework and model family. We first measure baseline results
for these models using their original sampler implementations, and then bring these samplers into our
unified framework using the formulas in Table 1, followed by our improvements. This allows us to
evaluate different practical choices and propose general improvements to the sampling process that
are applicable to all models.
We evaluate the ‚ÄúDDPM++ cont. (VP)‚Äù and ‚ÄúNCSN++ cont. (VE)‚Äù models by Song et al. [49]
trained on unconditional CIFAR-10 [29] at 32√ó32, corresponding to the variance preserving (VP) and
variance exploding (VE) formulations [49], originally inspired by DDPM [16] and SMLD [48]. We
also evaluate the ‚ÄúADM (dropout)‚Äù model by Dhariwal and Nichol [9] trained on class-conditional Im-
ageNet [8] at 64√ó64, corresponding to the improved DDPM (iDDPM) formulation [37]. This model
was trained using a discrete set of M = 1000 noise levels. Further details are given in Appendix C.
We evaluate the result quality in terms of Fr√©chet inception distance (FID) [15] computed between
50,000 generated images and all available real images. Figure 2 shows FID as a function of neural
function evaluations (NFE), i.e., how many times DŒ∏ is evaluated to produce a single image. Given
that the sampling process is dominated entirely by the cost of DŒ∏ , improvements in NFE translate
directly to sampling speed. The original deterministic samplers are shown in blue, and the reimple-
mentations of these methods in our unified framework (orange) yield similar but consistently better
results. The differences are explained by certain oversights in the original implementations as well
as our more careful treatment of discrete noise levels in the case of DDIM; see Appendix C. Note
that our reimplementations are fully specified by Algorithm 1 and Table 1, even though the original
codebases are structured very differently from each other.

                                                                      4
Algorithm 1 Deterministic sampling using Heun‚Äôs 2nd order method with arbitrary œÉ(t) and s(t).
 1: procedure H EUN S AMPLER(DŒ∏ (x; œÉ), œÉ(t),         s(t), ti‚àà{0,...,N } )
       sample x0 ‚àº N 0, œÉ 2 (t0 ) s2 (t0 ) I
                                              
 2:                                                                                        . Generate initial sample at t0
 3:    for i ‚àà {0,. . . , N ‚àí 1} do                                                  . Solve Eq. 4 over N time steps
                    œÉÃá(ti )    sÃá(ti )      œÉÃá(ti )s(ti )       xi
 4:        di ‚Üê              +         xi ‚àí               DŒ∏          ; œÉ(ti )                     . Evaluate dx/dt at ti
                    œÉ(ti )     s(ti )          œÉ(ti )          s(ti )
 5:        xi+1 ‚Üê xi + (ti+1 ‚àí ti )di                                                   . Take Euler step from ti to ti+1
                                                                                 nd
 6:         if œÉ(ti+1 ) 6= 0 then                                       . Apply 2 order correction unless œÉ goes to zero
                                                                                                   
                              œÉÃá(ti+1 )   sÃá(ti+1 )         œÉÃá(ti+1 )s(ti+1 )       xi+1
 7:             di0   ‚Üê                 +            xi+1 ‚àí                   DŒ∏            ; œÉ(ti+1 ) . Eval. dx/dt at ti+1
                              œÉ(ti+1 )    s(ti+1 )              œÉ(ti+1 )           s(ti+1 )
                                                   1
                                                         + 12 di0
                                                                    
 8:            xi+1 ‚Üê xi + (ti+1 ‚àí ti )              d
                                                   2 i
                                                                                        . Explicit trapezoidal rule at ti+1
 9:     return xN                                                                       . Return noise-free sample at tN


Discretization and higher-order integrators. Solving an ODE numerically is necessarily an
approximation of following the true solution trajectory. At each step, the solver introduces truncation
error that accumulates over the course of N steps. The local error generally scales superlinearly with
respect to step size, and thus increasing N improves the accuracy of the solution.
The commonly used Euler‚Äôs method is a first order ODE solver with O(h2 ) local error with respect
to step size h. Higher-order Runge‚ÄìKutta methods [50] scale more favorably but require multiple
evaluations of DŒ∏ per step. Linear multistep methods have also been recently proposed for sampling
diffusion models [31, 59]. Through extensive tests, we have found Heun‚Äôs 2nd order method [2]
(a.k.a. improved Euler, trapezoidal rule) ‚Äî previously explored in the context of diffusion models by
Jolicoeur-Martineau et al. [24] ‚Äî to provide an excellent tradeoff between truncation error and NFE.
As illustrated in Algorithm 1, it introduces an additional correction step for xi+1 to account for change
in dx/dt between ti and ti+1 . This correction leads to O(h3 ) local error at the cost of one additional
evaluation of DŒ∏ per step. Note that stepping to œÉ = 0 would result in a division by zero, so we revert
to Euler‚Äôs method in this case. We discuss the general family of 2nd order solvers in Appendix D.2.
The time steps {ti } determine how the step sizes and thus truncation errors are distributed between
different noise levels. We provide a detailed analysis in Appendix D.1, concluding that the step size
should decrease monotonically with decreasing œÉ and it does not need to vary on a per-sample basis.
We adopt a parameterized scheme where the time steps are defined according to a sequence of noise
levels {œÉi }, i.e., ti = œÉ ‚àí1 (œÉi ). We set œÉi<N = (Ai + B)œÅ and select the constants A and B so that
œÉ0 = œÉmax and œÉN ‚àí1 = œÉmin , which gives
                                       1              1        1 œÅ
                                              i
                       œÉi<N = œÉmax œÅ + N ‚àí1     (œÉmin œÅ ‚àí œÉmax œÅ )  and œÉN = 0.                   (5)
Here œÅ controls how much the steps near œÉmin are shortened at the expense of longer steps near œÉmax .
Our analysis in Appendix D.1 shows that setting œÅ = 3 nearly equalizes the truncation error at each
step, but that œÅ in range of 5 to 10 performs much better for sampling images. This suggests that
errors near œÉmin have a large impact. We set œÅ = 7 for the remainder of this paper.
Results for Heun‚Äôs method and Eq. 5 are shown as the green curves in Figure 2. We observe consistent
improvement in all cases: Heun‚Äôs method reaches the same FID as Euler‚Äôs method with considerably
lower NFE.

Trajectory curvature and noise schedule. The shape of the ODE solution trajectories is defined
by functions œÉ(t) and s(t). The choice of these functions offers a way to reduce the truncation errors
discussed above, as their magnitude can be expected to scale proportional to the curvature of dx/dt.
We argue that the best choice for these functions is œÉ(t) = t and s(t) = 1, which is also thechoice
made in DDIM [47]. With this choice, the ODE of Eq. 4 simplifies to dx/dt = x ‚àí D(x; t) /t and
œÉ and t become interchangeable.
An immediate consequence is that at any x and t, a single Euler step to t = 0 yields the denoised
image DŒ∏ (x; t). The tangent of the solution trajectory therefore always points towards the denoiser
output. This can be expected to change only slowly with the noise level, which corresponds to largely
linear solution trajectories. The 1D ODE sketch of Figure 3c supports this intuition; the solution
trajectories approach linear at both large and small noise levels, and have substantial curvature in
only a small region in between. The same effect can be seen with real data in Figure 1b, where the


                                                                    5
    x                                     x                                     x
                                                                               
                                                                               
                                                                                
                                                                               
                                                                               
t=                      t=                             t=                               
 (a) Variance preserving ODE [49] (b) Variance exploding ODE [49]                      (c) DDIM [47] / Our ODE
Figure 3: A sketch of ODE curvature in 1D where pdata is two Dirac peaks at x = ¬±1. Horizontal t
axis is chosen to show œÉ ‚àà [0, 25] in each plot, with insets showing œÉ ‚àà [0, 1] near the data. Example
local gradients are shown with black arrows. (a) Variance preserving ODE of Song et al. [49] has
solution trajectories that flatten out to horizontal lines at large œÉ. Local gradients start pointing
towards data only at small œÉ. (b) Variance exploding variant has extreme curvature near data and the
solution trajectories are curved everywhere. (c) With the schedule used by DDIM [47] and us, as
œÉ increases the solution trajectories approach straight lines that point towards the mean of data. As
œÉ ‚Üí 0, the trajectories become linear and point towards the data manifold.


change between different denoiser targets occurs in a relatively narrow œÉ range. With the advocated
schedule, this corresponds to high ODE curvature being limited to this same range.
The effect of setting œÉ(t) = t and s(t) = 1 is shown as the red curves in Figure 2. As DDIM already
employs these same choices, the red curve is identical to the green one for ImageNet-64. However,
VP and VE benefit considerably from switching away from their original schedules.

Discussion. The choices that we made in this section to improve deterministic sampling are
summarized in the Sampling part of Table 1. Together, they reduce the NFE needed to reach high-
quality results by a large factor: 7.3√ó for VP, 300√ó for VE, and 3.2√ó for DDIM, corresponding to
the highlighted NFE values in Figure 2. In practice, we can generate 26.3 high-quality CIFAR-10
images per second on a single NVIDIA V100. The consistency of improvements corroborates our
hypothesis that the sampling process is orthogonal to how each model was originally trained. As
further validation, we show results for the adaptive RK45 method [11] using our schedule as the
dashed black curves in Figure 2; the cost of this sophisticated ODE solver outweighs its benefits.

4        Stochastic sampling
Deterministic sampling offers many benefits, e.g., the ability to turn real images into their corre-
sponding latent representations by inverting the ODE. However, it tends to lead to worse output
quality [47, 49] than stochastic sampling that injects fresh noise into the image in each step. Given
that ODEs and SDEs recover the same distributions in theory, what exactly is the role of stochasticity?

Background. The SDEs of Song et al. [49] can be generalized [20, 58] as a sum of the probability
flow ODE of Eq. 1 and a time-varying Langevin diffusion SDE [14] (see Appendix B.5):
                                                                          p
  dx¬± = ‚àíœÉÃá(t)œÉ(t)‚àáx log p x; œÉ(t) dt ¬± Œ≤(t)œÉ(t)2 ‚àáx log p x; œÉ(t) dt + 2Œ≤(t)œÉ(t) dœât , (6)
                                                                   
        |             {z              } |               {z            } |        {z      }
                probability flow ODE (Eq. 1)             deterministic noise decay               noise injection
                                                 |                               {z                                }
                                                                       Langevin diffusion SDE

where œât is the standard Wiener process. dx+ and dx‚àí are now separate SDEs for moving forward
and backward in time, related by the time reversal formula of Anderson [1]. The Langevin term can
further be seen as a combination of a deterministic score-based denoising term and a stochastic noise
injection term, whose net noise level contributions cancel out. As such, Œ≤(t) effectively expresses the
relative rate at which existing noise is replaced with new noise. The SDEs of Song et al. [49] are
recovered with the choice Œ≤(t) = œÉÃá(t)/œÉ(t), whereby the score vanishes from the forward SDE.
This perspective reveals why stochasticity is helpful in practice: The implicit Langevin diffusion
drives the sample towards the desired marginal distribution at a given time, actively correcting for
any errors made in earlier sampling steps. On the other hand, approximating the Langevin term


                                                     6
Algorithm 2 Our stochastic sampler with œÉ(t) = t and s(t) = 1.
 1: procedure S TOCHASTIC S AMPLER        (DŒ∏ (x; œÉ), ti‚àà{0,...,N } , Œ≥i‚àà{0,...,N ‚àí1} , Snoise )
       sample x0 ‚àº N 0, t20 I
                                  
 2:                                                                                         ‚àö
                                                                             (                    
                                                                                min Schurn
                                                                                        N
                                                                                           , 2‚àí1       if ti ‚àà[Stmin ,Stmax ]
 3:    for i ‚àà {0, . . . , N ‚àí 1} do                                 . Œ≥i =
 4:                                2
           sample i ‚àº N 0, Snoise I
                                                                               0                      otherwise
 5:        tÃÇi ‚Üê ti + Œ≥ip  ti                                          . Select temporarily increased noise level tÃÇi
 6:        xÃÇi ‚Üê xi + tÃÇ2i ‚àí t2i i                                         . Add new noise to move from ti to tÃÇi
 7:        di ‚Üê xÃÇi ‚àí DŒ∏ (xÃÇi ; tÃÇi ) /tÃÇi                                                       . Evaluate dx/dt at tÃÇi
 8:        xi+1 ‚Üê xÃÇi + (ti+1 ‚àí tÃÇi )di                                            . Take Euler step from tÃÇi to ti+1
 9:        if ti+1 6= 0 then
                di0 ‚Üê xi+1 ‚àí DŒ∏ (xi+1 ; ti+1 ) /ti+1                                    . Apply 2nd order correction
                                                 
10:
11:             xi+1 ‚Üê xÃÇi + (ti+1 ‚àí tÃÇi ) 2 di + 21 di0
                                             1

12:    return xN


with discrete SDE solver steps introduces error in itself. Previous results [3, 24, 47, 49] suggest that
non-zero Œ≤(t) is helpful, but as far as we can tell, the implicit choice for Œ≤(t) in Song et al. [49] enjoys
no special properties. Hence, the optimal amount of stochasticity should be determined empirically.

Our stochastic sampler. We propose a stochastic sampler that combines our 2nd order deterministic
ODE integrator with explicit Langevin-like ‚Äúchurn‚Äù of adding and removing noise. A pseudocode is
given in Algorithm 2. At each step i, given the sample xi at noise level ti (= œÉ(ti )), we perform two
sub-steps. First, we add noise to the sample according to a factor Œ≥i ‚â• 0 to reach a higher noise level
tÃÇi = ti + Œ≥i ti . Second, from the increased-noise sample xÃÇi , we solve the ODE backward from tÃÇi to
ti+1 with a single step. This yields a sample xi+1 with noise level ti+1 , and the iteration continues.
We stress that this is not a general-purpose SDE solver, but a sampling procedure tailored for the
specific problem. Its correctness stems from the alternation of two sub-steps that each maintain the
correct distribution (up to truncation error in the ODE step). The predictor-corrector sampler of Song
et al. [49] has a conceptually similar structure to ours.
To analyze the main difference between our method and Euler‚ÄìMaruyama, we first note a subtle
discrepancy in the latter when discretizing Eq. 6. One can interpret Euler‚ÄìMaruyama as first adding
noise and then performing an ODE step, not from the intermediate state after noise injection, but
assuming that x and œÉ remained at the initial state at the beginning of the iteration step. In our
method, the parameters used to evaluate DŒ∏ on line 7 of Algorithm 2 correspond to the state after
noise injection, whereas an Euler‚ÄìMaruyama -like method would use xi ; ti instead of xÃÇi ; tÃÇi . In the
limit of ‚àÜt approaching zero there may be no difference between these choices, but the distinction
appears to become significant when pursuing low NFE with large steps.

Practical considerations. Increasing the amount of stochasticity is effective in correcting errors
made by earlier sampling steps, but it has its own drawbacks. We have observed (see Appendix E.1)
that excessive Langevin-like addition and removal of noise results in gradual loss of detail in the
generated images with all datasets and denoiser networks. There is also a drift toward oversaturated
colors at very low and high noise levels. We suspect that practical denoisers induce a slightly non-
conservative vector field in Eq. 3, violating the premises of Langevin diffusion and causing these
detrimental effects. Notably, our experiments with analytical denoisers (such as the one in Figure 1b)
have not shown such degradation.
If the degradation is caused by flaws in DŒ∏ (x; œÉ), they can only be remedied using heuristic means
during sampling. We address the drift toward oversaturated colors by only enabling stochasticity
within a specific range of noise levels ti ‚àà [Stmin , Stmax ]. For these noise levels, we define Œ≥i =
Schurn /N , where Schurn controls the overall amount of stochasticity. We further clamp Œ≥i to never
introduce more new noise than what is already present in the image. Finally, we have found that the
loss of detail can be partially counteracted by setting Snoise slightly above 1 to inflate the standard
deviation for the newly added noise. This suggests that a major component of the hypothesized
non-conservativity of DŒ∏ (x; œÉ) is a tendency to remove slightly too much noise ‚Äî most likely due to
regression toward the mean that can be expected to happen with any L2 -trained denoiser [30].

Evaluation. Figure 4 shows that our stochastic sampler outperforms previous samplers [24, 37, 49]
by a significant margin, especially at low step counts. Jolicoeur-Martineau et al. [24] use a standard


                                                             7
FID                                                        FID                                               FID
 3.2                                                        4.5                                               3.0
 3.0                                                                                                         2.8
                                                           4.0
 2.8                                                                                                         2.6
 2.6                                                       3.5                                               2.4
 2.4                                                                                                         2.2
                                        2.27
                                                           3.0
 2.2                                                                                                         2.0
         Deterministic               Stmin,tmax = [0, ‚àû]
                                                           2.5                                               1.8
 2.0     Stmin,tmax + Snoise = 1     Optimal settings
         Snoise = 1                  Original sampler                                                        1.6
 1.8     Jolicoeur-Martineau et al. [24]                                                            2.23                                           1.55
                                                           2.0                                               1.4
NFE=16 32       64      128     256     512    1024 2048      16     32   64   128   256   512   1024 2048      16     32   64   128   256   512   1024 2048

       (a) Uncond. CIFAR-10, VP                                    (b) Uncond. CIFAR-10, VE                          (c) Class-cond. ImageNet-64
Figure 4: Evaluation of our stochastic sampler (Algorithm 2). The purple curve corresponds to
optimal choices for {Schurn , Stmin , Stmax , Snoise }; orange, blue, and green correspond to disabling the
effects of Stmin,tmax and/or Snoise . The red curves show reference results for our deterministic sampler
(Algorithm 1), equivalent to setting Schurn = 0. The dashed black curves correspond to the original
stochastic samplers from previous work: Euler‚ÄìMaruyama [49] for VP, predictor-corrector [49] for
VE, and iDDPM [37] for ImageNet-64. The dots indicate lowest observed FID.

higher-order adaptive SDE solver [41] and its performance is a good baseline for such solvers in
general. Our sampler has been tailored to the use case by, e.g., performing noise injection and ODE
step sequentially, and it is not adaptive. It is an open question if adaptive solvers can be a net win
over a well-tuned fixed schedule in sampling diffusion models.
Through sampler improvements alone, we are able to bring the ImageNet-64 model that originally
achieved FID 2.07 [9] to 1.55 that is very close to the state-of-the-art; previously, FID 1.48 has been
reported for cascaded diffusion [17], 1.55 for classifier-free guidance [18], and 1.52 for StyleGAN-
XL [45]. While our results showcase the potential gains achievable through sampler improvements,
they also highlight the main shortcoming of stochasticity: For best results, one must make several
heuristic choices ‚Äî either implicit or explicit ‚Äî that depend on the specific model. Indeed, we had
to find the optimal values of {Schurn , Stmin , Stmax , Snoise } on a case-by-case basis using grid search
(Appendix E.2). This raises a general concern that using stochastic sampling as the primary means of
evaluating model improvements may inadvertently end up influencing the design choices related to
model architecture and training.

5      Preconditioning and training
There are various known good practices for training neural networks in a supervised fashion. For
example, it is advisable to keep input and output signal magnitudes fixed to, e.g., unit variance, and to
avoid large variation in gradient magnitudes on a per-sample basis [5, 21]. Training a neural network
to model D directly would be far from ideal ‚Äî for example, as the input x = y + n is a combination
of clean signal y and noise n ‚àº N (0, œÉ 2 I), its magnitude varies immensely depending on noise
level œÉ. For this reason, the common practice is to not represent DŒ∏ as a neural network directly, but
instead train a different network FŒ∏ from which DŒ∏ is derived.
Previous methods [37, 47, 49] address the input scaling via a œÉ-dependent normalization factor and
attempt to precondition the output by training FŒ∏ to predict n scaled to unit variance, from which the
signal is then reconstructed via DŒ∏ (x; œÉ) = x ‚àí œÉFŒ∏ (¬∑). This has the drawback that at large œÉ, the
network needs to fine-tune its output carefully to cancel out the existing noise n exactly and give the
output at the correct scale; note that any errors made by the network are amplified by a factor of œÉ.
In this situation, it would seem much easier to predict the expected output D(x; œÉ) directly. In the
same spirit as previous parameterizations that adaptively mix signal and noise (e.g., [10, 44, 53]),
we propose to precondition the neural network with a œÉ-dependent skip connection that allows it to
estimate either y or n, or something in between. We thus write DŒ∏ in the following form:
                                                                                  
                       DŒ∏ (x; œÉ) = cskip (œÉ) x + cout (œÉ) FŒ∏ cin (œÉ) x; cnoise (œÉ) ,                (7)
where FŒ∏ is the neural network to be trained, cskip (œÉ) modulates the skip connection, cin (œÉ) and
cout (œÉ) scale the input and output magnitudes, and cnoise (œÉ) maps noise level œÉ into a conditioning in-
put for F
         Œ∏ . Taking a weighted expectation
                                           of Eq. 2 over the noise levels gives the overall training loss
EœÉ,y,n Œª(œÉ) kD(y + n; œÉ) ‚àí yk22 , where œÉ ‚àº ptrain , y ‚àº pdata , and n ‚àº N (0, œÉ 2 I). The probabil-
ity of sampling a given noise level œÉ is given by ptrain (œÉ) and the corresponding weight is given by


                                                                                 8
Table 2: Evaluation of our training improvements. The starting point (config A) is VP & VE using
our deterministic sampler. At the end (configs E , F), VP & VE only differ in the architecture of FŒ∏ .
                                     CIFAR-10 [29] at 32√ó32      FFHQ [27] 64√ó64             AFHQv2 [7] 64√ó64
                                   Conditional   Unconditional     Unconditional               Unconditional
 Training configuration             VP    VE        VP    VE       VP        VE                 VP       VE
 A Baseline [49] (‚àó pre-trained)   2.48 3.11       3.01‚àó 3.77‚àó    3.39      25.95              2.58    18.52
 B + Adjust hyperparameters        2.18 2.48       2.51 2.94      3.13      22.53              2.43     23.12
 C + Redistribute capacity         2.08 2.52       2.31 2.83      2.78     41.62               2.54    15.04
 D + Our preconditioning           2.09 2.64       2.29 3.10      2.94       3.39              2.79      3.81
 E + Our loss function             1.88 1.86       2.05 1.99      2.60       2.81              2.29      2.28
 F + Non-leaky augmentation        1.79 1.79       1.97 1.98      2.39       2.53              1.96      2.16
 NFE                                35     35       35    35       79        79                 79       79


Œª(œÉ). We can equivalently express this loss with respect to the raw network output FŒ∏ in Eq. 7:
       h                                                                                   2i
 EœÉ,y,n Œª(œÉ) cout (œÉ)2 FŒ∏ cin (œÉ) ¬∑ (y + n); cnoise (œÉ) ‚àí cout1(œÉ) y ‚àí cskip (œÉ) ¬∑ (y + n) 2 . (8)
                                                       
         |    {z     } |                {z             } |                {z              }
             effective weight           network output                  effective training target

This form reveals the effective training target of FŒ∏ , allowing us to determine suitable choices for the
preconditioning functions from first principles. As detailed in Appendix B.6, we derive our choices
shown in Table 1 by requiring network inputs and training targets to have unit variance (cin , cout ), and
amplifying errors in FŒ∏ as little as possible (cskip ). The formula for cnoise is chosen empirically.
Table 2 shows FID for a series of training setups, evaluated using our deterministic sampler from
Section 3. We start with the baseline training setup of Song et al. [49], which differs considerably
between the VP and VE cases; we provide separate results for each (config A). To obtain a more
meaningful point of comparison, we re-adjust the basic hyperparameters (config B) and improve the
expressive power of the model (config C) by removing the lowest-resolution layers and doubling the
capacity of the highest-resolution layers instead; see Appendix F.3 for further details. We then replace
the original choices of {cin , cout , cnoise , cskip } with our preconditioning (config D), which keeps the
results largely unchanged ‚Äî except for VE that improves considerably at 64√ó64 resolution. Instead
of improving FID per se, the main benefit of our preconditioning is that it makes the training more
robust, enabling us to turn our focus on redesigning the loss function without adverse effects.

Loss weighting and sampling. Eq. 8 shows that training FŒ∏ as preconditioned in Eq. 7 incurs
an effective per-sample loss weight of Œª(œÉ)cout (œÉ)2 . To balance the effective loss weights, we set
Œª(œÉ) = 1/cout (œÉ)2 , which also equalizes the initial training loss over the entire œÉ range as shown in
Figure 5a (green curve). Finally, we need to select ptrain (œÉ), i.e., how to choose noise levels during
training. Inspecting the per-œÉ loss after training (blue and orange curves) reveals that a significant
reduction is possible only at intermediate noise levels; at very low levels, it is both difficult and
irrelevant to discern the vanishingly small noise component, whereas at high levels the training targets
are always dissimilar from the correct answer that approaches dataset average. Therefore, we target
the training efforts to the relevant range using a simple log-normal distribution for ptrain (œÉ) as detailed
in Table 1 and illustrated in Figure 5a (red curve).
Table 2 shows that our proposed ptrain and Œª (config E) lead to a dramatic improvement in FID
in all cases when used in conjunction with our preconditioning (config D). In concurrent work,
Choi et al. [6] propose a similar scheme to prioritize noise levels that are most relevant w.r.t. forming
the perceptually recognizable content of the image. However, they only consider the choice of Œª in
isolation, which results in a smaller overall improvement.

Augmentation regularization. To prevent potential overfitting that often plagues diffusion models
with smaller datasets, we borrow an augmentation pipeline from the GAN literature [25]. The pipeline
consists of various geometric transformations (see Appendix F.2) that we apply to a training image
prior to adding noise. To prevent the augmentations from leaking to the generated images, we provide
the augmentation parameters as a conditioning input to FŒ∏ ; during inference we set the them to zero
to guarantee that only non-augmented images are generated. Table 2 shows that data augmentation
provides a consistent improvement (config F) that yields new state-of-the-art FIDs of 1.79 and 1.97
for conditional and unconditional CIFAR-10, beating the previous records of 1.85 [45] and 2.10 [53].

                                                         9
loss                                                  FID                                          FID
          Loss after init        CIFAR-10                           VP, original   VP, our model        2.66           Original   Our model
 1.4                                                   4.0                                          2.6
          Distribution of œÉ      FFHQ-64                            VE, original   VE, our model
 1.2                                                                                               2.4
 1.0                                                  3.5                                          2.2 2.22
 0.8                                                                                               2.0
                                                      3.0
 0.6                                                                                               1.8
 0.4                                                  2.5                                          1.6
                                                                                                                                  1.57
 0.2                                                                                               1.4
                                                      2.0                                                       1.36
 0.0                                                                                               1.2
    œÉ=0.005 0.02    0.1       0.5 1 2   5 10 20 50   Schurn =0 10 20 30 40 50 60 70 80 90 100 Schurn =0 10 20 30 40 50 60 70 80 90 100

       (a) Loss & noise distribution                         (b) Stochasticity on CIFAR-10          (c) Stochasticity on ImageNet-64
Figure 5: (a) Observed initial (green) and final loss per noise level, representative of the the 32√ó32
(blue) and 64√ó64 (orange) models considered in this paper. The shaded regions represent the standard
deviation over 10k random samples. Our proposed training sample density is shown by the dashed
red curve. (b) Effect of Schurn on unconditional CIFAR-10 with 256 steps (NFE = 511). For the
original training setup of Song et al. [49], stochastic sampling is highly beneficial (blue, green), while
deterministic sampling (Schurn = 0) leads to relatively poor FID. For our training setup, the situation
is reversed (orange, red); stochastic sampling is not only unnecessary but harmful. (c) Effect of Schurn
on class-conditional ImageNet-64 with 256 steps (NFE = 511). In this more challenging scenario,
stochastic sampling turns out to be useful again. Our training setup improves the results for both
deterministic and stochastic sampling.

Stochastic sampling revisited. Interestingly, the relevance of stochastic sampling appears to
diminish as the model itself improves, as shown in Figure 5b,c. When using our training setup in
CIFAR-10 (Figure 5b), the best results were obtained with deterministic sampling, and any amount
of stochastic sampling was detrimental.

ImageNet-64. As a final experiment, we trained a class-conditional ImageNet-64 model from
scratch using our proposed training improvements. This model achieved a new state-of-the-art FID of
1.36 compared to the previous record of 1.48 [17]. We used the ADM architecture [9] with no changes,
and trained it using our config E with minimal tuning; see Appendix F.3 for details. We did not find
overfitting to be a concern, and thus chose to not employ augmentation regularization. As shown
in Figure 5c, the optimal amount of stochastic sampling was much lower than with the pre-trained
model, but unlike with CIFAR-10, stochastic sampling was clearly better than deterministic sampling.
This suggests that more diverse datasets continue to benefit from stochastic sampling.

6      Conclusions

Our approach of putting diffusion models to a common framework exposes a modular design. This
allows a targeted investigation of individual components, potentially helping to better cover the viable
design space. In our tests this let us simply replace the samplers in various earlier models, drastically
improving the results. For example, in ImageNet-64 our sampler turned an average model (FID 2.07)
to a challenger (1.55) for the previous SOTA model (1.48) [17], and with training improvements
achieved SOTA FID of 1.36. We also obtained new state-of-the-art results on CIFAR-10 while using
only 35 model evaluations, deterministic sampling, and a small network. The current high-resolution
diffusion models rely either on separate super-resolution steps [17, 36, 40], subspace projection [23],
very large networks [9, 49], or hybrid approaches [39, 42, 53] ‚Äî we believe that our contributions are
orthogonal to these extensions. That said, many of our parameter values may need to be re-adjusted
for higher resolution datasets. Furthermore, we feel that the precise interaction between stochastic
sampling and the training objective remains an interesting question for future work.

Societal impact. Our advances in sample quality can potentially amplify negative societal effects
when used in a large-scale system like DALL¬∑E 2, including types of disinformation or emphasizing
sterotypes and harmful biases [34]. The training and sampling of diffusion models needs a lot of
electricity; our project consumed ‚àº250MWh on an in-house cluster of NVIDIA V100s.

Acknowledgments. We thank Jaakko Lehtinen, Ming-Yu Liu, Tuomas Kynk√§√§nniemi, Axel Sauer,
Arash Vahdat, and Janne Hellsten for discussions and comments, and Tero Kuosmanen, Samuel
Klenberg, and Janne Hellsten for maintaining our compute infrastructure.


                                                                            10
References
 [1] B. D. Anderson. Reverse-time diffusion equation models. Stochastic Processes and their Applications,
     12(3):313‚Äì326, 1982.
 [2] U. M. Ascher and L. R. Petzold. Computer Methods for Ordinary Differential Equations and Differential-
     Algebraic Equations. Society for Industrial and Applied Mathematics, 1998.
 [3] F. Bao, C. Li, J. Zhu, and B. Zhang. Analytic-DPM: an analytic estimate of the optimal reverse variance in
     diffusion probabilistic models. In Proc. ICLR, 2022.
 [4] D. Baranchuk, A. Voynov, I. Rubachev, V. Khrulkov, and A. Babenko. Label-efficient semantic segmenta-
     tion with diffusion models. In Proc. ICLR, 2022.
 [5] C. M. Bishop. Neural networks for pattern recognition. Oxford University Press, USA, 1995.
 [6] J. Choi, J. Lee, C. Shin, S. Kim, H. Kim, and S. Yoon. Perception prioritized training of diffusion models.
     In Proc. CVPR, 2022.
 [7] Y. Choi, Y. Uh, J. Yoo, and J.-W. Ha. StarGAN v2: Diverse image synthesis for multiple domains. In Proc.
     CVPR, 2020.
 [8] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A large-scale hierarchical image
     database. In Proc. CVPR, 2009.
 [9] P. Dhariwal and A. Q. Nichol. Diffusion models beat GANs on image synthesis. In Proc. NeurIPS, 2021.
[10] T. Dockhorn, A. Vahdat, and K. Kreis. Score-based generative modeling with critically-damped Langevin
     diffusion. In Proc. ICLR, 2022.
[11] J. R. Dormand and P. J. Prince. A family of embedded Runge-Kutta formulae. Journal of computational
     and applied mathematics, 6(1):19‚Äì26, 1980.
[12] J. B. J. Fourier, G. Darboux, et al. Th√©orie analytique de la chaleur, volume 504. Didot Paris, 1822.
[13] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio.
     Generative adversarial networks. In Proc. NIPS, 2014.
[14] U. Grenander and M. I. Miller. Representations of knowledge in complex systems. Journal of the Royal
     Statistical Society: Series B (Methodological), 56(4):549‚Äì581, 1994.
[15] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter. GANs trained by a two time-scale
     update rule converge to a local Nash equilibrium. In Proc. NIPS, 2017.
[16] J. Ho, A. Jain, and P. Abbeel. Denoising diffusion probabilistic models. In Proc. NeurIPS, 2020.
[17] J. Ho, C. Saharia, W. Chan, D. J. Fleet, M. Norouzi, and T. Salimans. Cascaded diffusion models for high
     fidelity image generation. Journal of Machine Learning Research, 23, 2022.
[18] J. Ho and T. Salimans. Classifier-free diffusion guidance. In NeurIPS 2021 Workshop on Deep Generative
     Models and Downstream Applications, 2021.
[19] J. Ho, T. Salimans, A. A. Gritsenko, W. Chan, M. Norouzi, and D. J. Fleet. Video diffusion models. In
     Proc. ICLR Workshop on Deep Generative Models for Highly Structured Data, 2022.
[20] C.-W. Huang, J. H. Lim, and A. C. Courville. A variational perspective on diffusion-based generative
     models and score matching. In Proc. NeurIPS, 2021.
[21] L. Huang, J. Qin, Y. Zhou, F. Zhu, L. Liu, and L. Shao. Normalization techniques in training DNNs:
     Methodology, analysis and application. CoRR, abs/2009.12836, 2020.
[22] A. Hyv√§rinen. Estimation of non-normalized statistical models by score matching. Journal of Machine
     Learning Research, 6(24):695‚Äì709, 2005.
[23] B. Jing, G. Corso, R. Berlinghieri, and T. Jaakkola. Subspace diffusion generative models. In Proc. ECCV,
     2022.
[24] A. Jolicoeur-Martineau, K. Li, R. Pich√©-Taillefer, T. Kachman, and I. Mitliagkas. Gotta go fast when
     generating data with score-based models. CoRR, abs/2105.14080, 2021.
[25] T. Karras, M. Aittala, J. Hellsten, S. Laine, J. Lehtinen, and T. Aila. Training generative adversarial
     networks with limited data. In Proc. NeurIPS, 2020.
[26] T. Karras, M. Aittala, S. Laine, E. H√§rk√∂nen, J. Hellsten, J. Lehtinen, and T. Aila. Alias-free generative
     adversarial networks. In Proc. NeurIPS, 2021.
[27] T. Karras, S. Laine, and T. Aila. A style-based generator architecture for generative adversarial networks.
     In Proc. CVPR, 2018.
[28] Z. Kong, W. Ping, J. Huang, K. Zhao, and B. Catanzaro. DiffWave: A versatile diffusion model for audio
     synthesis. In Proc. ICLR, 2021.
[29] A. Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of
     Toronto, 2009.
[30] J. Lehtinen, J. Munkberg, J. Hasselgren, S. Laine, T. Karras, M. Aittala, and T. Aila. Noise2Noise:
     Learning image restoration without clean data. In Proc. ICML, 2018.
[31] L. Liu, Y. Ren, Z. Lin, and Z. Zhao. Pseudo numerical methods for diffusion models on manifolds. In
     Proc. ICLR, 2022.
[32] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu. DPM-Solver: A fast ODE solver for diffusion
     probabilistic model sampling in around 10 steps. In Proc. NeurIPS, 2022.


                                                      11
[33] E. Luhman and T. Luhman. Knowledge distillation in iterative generative models for improved sampling
     speed. CoRR, abs/2101.02388, 2021.
[34] P. Mishkin, L. Ahmad, M. Brundage, G. Krueger, and G. Sastry. DALL¬∑E 2 preview ‚Äì risks and limitations.
     OpenAI, 2022.
[35] E. Nachmani and S. Dovrat. Zero-shot translation using diffusion models. CoRR, abs/2111.01471, 2021.
[36] A. Nichol, P. Dhariwal, A. Ramesh, P. Shyam, P. Mishkin, B. McGrew, I. Sutskever, and M. Chen. GLIDE:
     Towards photorealistic image generation and editing with text-guided diffusion models. In Proc. ICML,
     2022.
[37] A. Q. Nichol and P. Dhariwal. Improved denoising diffusion probabilistic models. In Proc. ICML, volume
     139, pages 8162‚Äì8171, 2021.
[38] V. Popov, I. Vovk, V. Gogoryan, T. Sadekova, and M. Kudinov. Grad-TTS: A diffusion probabilistic model
     for text-to-speech. In Proc. ICML, volume 139, pages 8599‚Äì8608, 2021.
[39] K. Preechakul, N. Chatthee, S. Wizadwongsa, and S. Suwajanakorn. Diffusion autoencoders: Toward a
     meaningful and decodable representation. In Proc. CVPR, 2022.
[40] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. Chen. Hierarchical text-conditional image generation
     with CLIP latents. Technical report, OpenAI, 2022.
[41] A. J. Roberts. Modify the improved Euler scheme to integrate stochastic differential equations. CoRR,
     abs/1210.0933, 2012.
[42] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer. High-resolution image synthesis with
     latent diffusion models. In Proc. CVPR, 2022.
[43] C. Saharia, W. Chan, H. Chang, C. A. Lee, J. Ho, T. Salimans, D. J. Fleet, and M. Norouzi. Palette:
     Image-to-image diffusion models. In Proc. SIGGRAPH, 2022.
[44] T. Salimans and J. Ho. Progressive distillation for fast sampling of diffusion models. In Proc. ICLR, 2022.
[45] A. Sauer, K. Schwarz, and A. Geiger. StyleGAN-XL: Scaling StyleGAN to large diverse datasets. In Proc.
     SIGGRAPH, 2022.
[46] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli. Deep unsupervised learning using
     nonequilibrium thermodynamics. In Proc. ICML, pages 2256‚Äì2265, 2015.
[47] J. Song, C. Meng, and S. Ermon. Denoising diffusion implicit models. In Proc. ICLR, 2021.
[48] Y. Song and S. Ermon. Generative modeling by estimating gradients of the data distribution. In Proc.
     NeurIPS, 2019.
[49] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole. Score-based generative
     modeling through stochastic differential equations. In Proc. ICLR, 2021.
[50] E. S√ºli and D. F. Mayers. An Introduction to Numerical Analysis. Cambridge University Press, 2003.
[51] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the Inception architecture for
     computer vision. In Proc. CVPR, 2016.
[52] M. Tancik, P. P. Srinivasan, B. Mildenhall, S. Fridovich-Keil, N. Raghavan, U. Singhal, R. Ramamoorthi,
     J. T. Barron, and R. Ng. Fourier features let networks learn high frequency functions in low dimensional
     domains. In Proc. NeurIPS, 2020.
[53] A. Vahdat, K. Kreis, and J. Kautz. Score-based generative modeling in latent space. In Proc. NeurIPS,
     2021.
[54] P. Vincent. A connection between score matching and denoising autoencoders. Neural Computation,
     23(7):1661‚Äì1674, 2011.
[55] D. Watson, W. Chan, J. Ho, and M. Norouzi. Learning fast samplers for diffusion models by differentiating
     through sample quality. In Proc. ICLR, 2022.
[56] D. Watson, J. Ho, M. Norouzi, and W. Chan. Learning to efficiently sample from diffusion probabilistic
     models. CoRR, abs/2106.03802, 2021.
[57] J. Wolleb, R. Sandk√ºhler, F. Bieder, P. Valmaggia, and P. C. Cattin. Diffusion models for implicit image
     segmentation ensembles. In Medical Imaging with Deep Learning, 2022.
[58] Q. Zhang and Y. Chen. Diffusion normalizing flow. In Proc. NeurIPS, 2021.
[59] Q. Zhang and Y. Chen. Fast sampling of diffusion models with exponential integrator. CoRR,
     abs/2204.13902, 2022.




                                                      12
Checklist
    1. For all authors...
        (a) Do the main claims made in the abstract and introduction accurately reflect the paper‚Äôs
            contributions and scope? [Yes]
        (b) Did you describe the limitations of your work? [Yes] Section 6. The main limitations
            of the analysis relate to the set of tested datasets and their limited resolution.
        (c) Did you discuss any potential negative societal impacts of your work? [Yes] Section 6.
        (d) Have you read the ethics review guidelines and ensured that your paper conforms to
            them? [Yes]
    2. If you are including theoretical results...
        (a) Did you state the full set of assumptions of all theoretical results? [No] We follow
            common application-specific assumptions about the probability distributions, functions
            and other components, but do not exhaustively specify them, or consider pathological
            corner cases.
        (b) Did you include complete proofs of all theoretical results? [No] Our equations and
            algorithms build on previously known results, and highlight their practical aspects
            through mostly readily verifiable algebraic manipulations (Appendix B). We do not
            explicitly present all details of the derivations, and assume that the previous results are
            sufficiently rigorously proven in the respective literature.
    3. If you ran experiments...
        (a) Did you include the code, data, and instructions needed to reproduce the main experi-
            mental results (either in the supplemental material or as a URL)? [Yes] Our implemen-
            tation and pre-trained models are available at https://github.com/NVlabs/edm
        (b) Did you specify all the training details (e.g., data splits, hyperparameters, how they
            were chosen)? [Yes] Appendix F.
        (c) Did you report error bars (e.g., with respect to the random seed after running experi-
            ments multiple times)? [Yes] Shaded regions in Figures 4 and 5.
        (d) Did you include the total amount of compute and the type of resources used (e.g., type
            of GPUs, internal cluster, or cloud provider)? [Yes] Section 6.
    4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
        (a) If your work uses existing assets, did you cite the creators? [Yes]
        (b) Did you mention the license of the assets? [Yes] Appendix F.5.
        (c) Did you include any new assets either in the supplemental material or as a URL? [No]
        (d) Did you discuss whether and how consent was obtained from people whose data you‚Äôre
            using/curating? [N/A]
        (e) Did you discuss whether the data you are using/curating contains personally identifiable
            information or offensive content? [N/A]
    5. If you used crowdsourcing or conducted research with human subjects...
        (a) Did you include the full text of instructions given to participants and screenshots, if
            applicable? [N/A]
        (b) Did you describe any potential participant risks, with links to Institutional Review
            Board (IRB) approvals, if applicable? [N/A]
        (c) Did you include the estimated hourly wage paid to participants and the total amount
            spent on participant compensation? [N/A]




                                                13
Appendices
A     Additional results
Figure 6 presents generated images for class-conditional ImageNet-64 [8] using the pre-trained
ADM model by Dhariwal and Nichol [9]. The original DDIM [47] and iDDPM [37] samplers are
compared to ours in both deterministic and stochastic settings (Sections 3 and 4). Figure 7 shows the
corresponding results that we obtain by training the model from scratch using our improved training
configuration (Section 5).
The original samplers and training configurations by Song et al. [49] are compared to ours in
Figures 8 and 9 (unconditional CIFAR-10 [29]), Figure 10 (class-conditional CIFAR-10), and
Figure 11 (FFHQ [27] and AFHQv2 [7]). For ease of comparison, the same latent codes x0 are used
for each dataset/scenario across different training configurations and ODE choices. Figure 12 shows
generated image quality with various NFE when using deterministic sampling.
Tables 3 and 4 summarize the numerical results on deterministic and stochastic sampling methods in
various datasets, previously shown as functions of NFE in Figures 2 and 4.

B     Derivation of formulas
B.1   Original ODE / SDE formulation from previous work

Song et al. [49] define their forward SDE (Eq. 5 in [49]) as
                                    dx = f (x, t) dt + g(t) dœât ,                                  (9)
where œât is the standard Wiener process and f (¬∑, t) : Rd ‚Üí Rd and g(¬∑) : R ‚Üí R are the drift and
diffusion coefficients, respectively, where d is the dimensionality of the dataset. These coefficients
are selected differently for the variance preserving (VP) and variance exploding (VE) formulations,
and f (¬∑) is always of the form f (x, t) = f (t) x, where f (¬∑) : R ‚Üí R. Thus, the SDE can be
equivalently written as
                                      dx = f (t) x dt + g(t) dœât .                                (10)

The perturbation kernels of this SDE (Eq. 29 in [49]) have the general form
                     p0t x(t) | x(0) = N x(t); s(t) x(0), s(t)2 œÉ(t)2 I ,
                                                                           
                                                                                                 (11)
where N (x; ¬µ, Œ£) denotes the probability density function of N (¬µ, Œ£) evaluated at x,
                             Z t                              sZ
                                                                    t
                                                                      g(Œæ)2
                                           
                  s(t) = exp      f (Œæ) dŒæ , and œÉ(t) =                   2
                                                                            dŒæ.                  (12)
                                0                                  0 s(Œæ)


The marginal distribution pt (x) is obtained by integrating the perturbation kernels over x(0):
                                        Z
                              pt (x) =      p0t (x | x0 ) pdata (x0 ) dx0 .                     (13)
                                         Rd

Song et al. [49] define the probability flow ODE (Eq. 13 in [49]) so that it obeys this same pt (x):
                              dx = f (t) x ‚àí 21 g(t)2 ‚àáx log pt (x) dt.
                                                                  
                                                                                                  (14)

B.2   Our ODE formulation (Eq. 1 and Eq. 4)

The original ODE formulation (Eq. 14) is built around the functions f and g that correspond directly
to specific terms that appear in the formula; the properties of the marginal distribution (Eq. 12) can
only be derived indirectly based on these functions. However, f and g are of little practical interest
in themselves, whereas the marginal distributions are of utmost importance in terms of training the
model in the first place, bootstrapping the sampling process, and understanding how the ODE behaves
in practice. Given that the idea of the probability flow ODE is to match a particular set of marginal


                                                 14
          Deterministic, Original sampler (DDIM)              Deterministic, Our sampler (Alg. 1)
Ostrich




                                                    Ostrich
Beagle




                                                    Beagle
Balloon




                                                    Balloon
Pizza




                                                    Pizza
Valley




                                                    Valley
Daisy




                                                    Daisy
Agaric




                                                    Agaric




                    FID 2.91   NFE 250                                FID 2.66   NFE 79

          Stochastic, Original sampler (iDDPM)                 Stochastic, Our sampler (Alg. 2)
Ostrich




                                                    Ostrich
Beagle




                                                    Beagle
Balloon




                                                    Balloon
Pizza




                                                    Pizza
Valley




                                                    Valley
Daisy




                                                    Daisy
Agaric




                                                    Agaric




                    FID 2.01   NFE 512                               FID 1.55    NFE 1023

Figure 6: Results for different samplers on class-conditional ImageNet [8] at 64√ó64 resolution, using
the pre-trained model by Dhariwal and Nichol [9]. The cases correspond to dots in Figures 2c and 4c.



                                                   15
                         Deterministic, Our sampler & training configuration

 Ostrich
 Beagle
 Balloon
 Pizza
 Valley
 Daisy
 Agaric




                                           FID 2.23    NFE 79

                           Stochastic, Our sampler & training configuration
 Ostrich
 Beagle
 Balloon
 Pizza
 Valley
 Daisy
 Agaric




                                          FID 1.36     NFE 511

Figure 7: Results for our training configuration on class-conditional ImageNet [8] at 64√ó64 resolution,
using our deterministic and stochastic samplers.



                                                  16
   Deterministic, Original sampler (p.flow), VP        Deterministic, Original sampler (p.flow), VE




                FID 2.94   NFE 256                                 FID 5.45    NFE 8192

     Deterministic, Our sampler (Alg. 1), VP             Deterministic, Our sampler (Alg. 1), VE




                FID 3.01   NFE 35                                   FID 3.82   NFE 27

     Stochastic, Original sampler (E‚ÄìM), VP              Stochastic, Original sampler (P‚ÄìC), VE




               FID 2.55    NFE 1024                                FID 2.46    NFE 2048

      Stochastic, Our sampler (Alg. 2), VP                Stochastic, Our sampler (Alg. 2), VE




                FID 2.27   NFE 511                                 FID 2.23    NFE 2047

Figure 8: Results for different samplers on unconditional CIFAR-10 [29] at 32√ó32 resolution, using
the pre-trained models by Song et al. [49]. The cases correspond to dots in Figures 2a,b and 4a,b.



                                                  17
         Original training (config A), VP                 Original training (config A), VE




                FID 3.01   NFE 35                                FID 3.77   NFE 35

           Our training (config F), VP                      Our training (config F), VE




                FID 1.97 NFE 35                                  FID 1.98   NFE 35

Figure 9: Results for different training configurations on unconditional CIFAR-10 [29] at 32√ó32
resolution, using our deterministic sampler with the same set of latent codes (x0 ) in each case.




                                               18
         Original training (config A), VP                  Original training (config A), VE
Plane




                                                  Plane
Car




                                                  Car
Bird




                                                  Bird
Cat




                                                  Cat
Deer




                                                  Deer
Dog




                                                  Dog
Frog




                                                  Frog
Horse




                                                  Horse
Ship




                                                  Ship
Truck




                                                  Truck




                FID 2.48   NFE 35                                  FID 3.11   NFE 35

            Our training (config F), VP                       Our training (config F), VE
Plane




                                                  Plane
Car




                                                  Car
Bird




                                                  Bird
Cat




                                                  Cat
Deer




                                                  Deer
Dog




                                                  Dog
Frog




                                                  Frog
Horse




                                                  Horse
Ship




                                                  Ship
Truck




                                                  Truck




                FID 1.79 NFE 35                                    FID 1.79   NFE 35

Figure 10: Results for different training configurations on class-conditional CIFAR-10 [29] at 32√ó32
resolution, using our deterministic sampler with the same set of latent codes (x0 ) in each case.




                                                19
     FFHQ, Original training (config A), VP           FFHQ, Original training (config A), VE




                FID 3.39   NFE 79                               FID 25.95   NFE 79

       FFHQ, Our training (config F), VP                FFHQ, Our training (config F), VE




                FID 2.39 NFE 79                                  FID 2.53   NFE 79

    AFHQv2, Original training (config A), VP         AFHQv2, Original training (config A), VE




                FID 2.58   NFE 79                               FID 18.52   NFE 79

      AFHQv2, Our training (config F), VP              AFHQv2, Our training (config F), VE




                FID 1.96 NFE 79                                  FID 2.16   NFE 79

Figure 11: Results for different training configurations on FFHQ [27] and AFHQv2 [7] at 64√ó64
resolution, using our deterministic sampler with the same set of latent codes (x0 ) in each case.




                                               20
  Class-conditional ImageNet-64, Pre-trained        Class-conditional CIFAR-10, Our training, VP




FID 87.16      12.39       3.56        2.66         85.46   35.47   14.32   6.72   4.22   2.48   1.86   1.79
NFE 7           11          19          79            7       9      11      13     15     19     27     35

     Unconditional FFHQ, Our training, VP             Unconditional AFHQv2, Our Training, VP




FID 142.34     29.22       5.13        2.39            61.57           13.68          3.00          1.96
NFE 7           11          19          79               7              11             19            79


Figure 12: Image quality and FID as a function of NFE using our deterministic sampler. At 32√ó32
resolution, reasonable image quality is reached around NFE = 13, but FID keeps improving until
NFE = 35. At 64√ó64 resolution, reasonable image quality is reached around NFE = 19, but FID
keeps improving until NFE = 79.




                                               21
Table 3: Evaluation of our improvements to deterministic sampling. The values correspond to the
curves shown in Figure 2. We summarize each curve with two key values: the lowest observed FID
for any NFE (‚ÄúFID‚Äù), and the lowest NFE whose FID is within 3% of the lowest FID (‚ÄúNFE‚Äù). The
values marked with ‚Äú‚Äì‚Äù are identical to the ones above them, because our sampler uses the same œÉ(t)
and s(t) as DDIM.
                                        Unconditional CIFAR-10 at 32√ó32          Class-conditional
                                           VP                     VE               ImageNet-64
      Sampling method                FID ‚Üì    NFE ‚Üì        FID ‚Üì     NFE ‚Üì       FID ‚Üì     NFE ‚Üì
      Original sampler [49, 9]        2.85      256         5.45     8192         2.85       250
      Our Algorithm 1                 2.79      512         4.78     8192         2.73       384
      + Heun & our ti                 2.88      255         4.23      191         2.64        79
      + Our œÉ(t) & s(t)               2.93       35         3.73       27            ‚Äì         ‚Äì
      Black-box RK45                  2.94     115          3.69       93         2.66      131


Table 4: Evaluation and ablations of our improvements to stochastic sampling. The values correspond
to the curves shown in Figure 4.
                                              Unconditional CIFAR-10 at 32√ó32        Class-conditional
                                                  VP                  VE               ImageNet-64
  Sampling method                           FID ‚Üì NFE ‚Üì         FID ‚Üì NFE ‚Üì           FID ‚Üì NFE ‚Üì
  Deterministic baseline (Alg. 1)            2.93       35       3.73       27         2.64       79
  Alg. 2, Stmin,tmax = [0, ‚àû], Snoise = 1    2.69       95       2.97      383        1.86      383
  Alg. 2, Stmin,tmax = [0, ‚àû]                2.54     127        2.51      511        1.63      767
  Alg. 2, Snoise = 1                         2.52       95       2.84      191        1.84      255
  Alg. 2, Optimal settings                   2.27     383        2.23      767        1.55      511
  Previous work [49, 9]                      2.55     768        2.46     1024         2.01     384


distributions, it makes sense to treat the marginal distributions as first-class citizens and define the
ODE directly based on œÉ(t) and s(t), eliminating the need for f (t) and g(t).
Let us start by expressing the marginal distribution of Eq. 13 in closed form:
                              Z
                  pt (x) =         p0t (x | x0 ) pdata (x0 ) dx0                                     (15)
                               Rd
                              Z               h                              i
                         =         pdata (x0 ) N x; s(t) x0 , s(t)2 œÉ(t)2 I dx0                      (16)
                                 d
                              ZR              h                                 i
                         =         pdata (x0 ) s(t)‚àíd N x/s(t); x0 , œÉ(t)2 I dx0                     (17)
                               Rd
                                      Z
                         = s(t)‚àíd           pdata (x0 ) N x/s(t); x0 , œÉ(t)2 I dx0
                                                                              
                                                                                                     (18)
                                          d
                                       hR                      i
                         = s(t)‚àíd pdata ‚àó N 0, œÉ(t)2 I x/s(t) ,
                                                                        
                                                                                                     (19)

where pa ‚àó pb denotes the convolution of probability density functions pa and pb . The expression
inside the brackets corresponds to a mollified version of pdata obtained by adding i.i.d. Gaussian noise
to the samples. Let us denote this distribution by p(x; œÉ):
            p(x; œÉ) = pdata ‚àó N 0, œÉ(t)2 I        and pt (x) = s(t)‚àíd p x/s(t); œÉ(t) .
                                                                                          
                                                                                                    (20)

We can now express the probability flow ODE (Eq. 14) using p(x; œÉ) instead of pt (x):
          dx = f (t)x ‚àí 21 g(t)2 ‚àáx log pt (x) dt
                                                 
                                                                                                     (21)
                = f (t)x ‚àí 12 g(t)2 ‚àáx log s(t)‚àíd p x/s(t); œÉ(t)
                                                                  
                                                                         dt                          (22)
                               1      2           ‚àíd
                                                                            
                = f (t)x ‚àí 2 g(t) ‚àáx log s(t) + ‚àáx log p x/s(t); œÉ(t)              dt                (23)
                                      2
                = f (t)x ‚àí 21 g(t) ‚àáx log p x/s(t); œÉ(t) dt.
                                                           
                                                                                                     (24)


                                                     22
Next, let us rewrite f (t) in terms of s(t) based on Eq. 12:
                                    Z t           
                                exp       f (Œæ) dŒæ    = s(t)                                            (25)
                                         0
                                         Z       t
                                           f (Œæ) dŒæ = log s(t)                                          (26)
                                             0
                                Z t          
                                                             
                               d     f (Œæ) dŒæ dt = d log s(t) /dt                                       (27)
                                    0
                                                     f (t)    = sÃá(t)/s(t).                             (28)

Similarly, we can also rewrite g(t) in terms of œÉ(t):
                                 sZ
                                      t
                                         g(Œæ)2
                                             2
                                               dŒæ = œÉ(t)                                                (29)
                                     0 s(Œæ)
                                   Z t
                                         g(Œæ)2
                                             2
                                               dŒæ = œÉ(t)2                                               (30)
                                     0 s(Œæ)
                           Z t
                                  g(Œæ)2
                                             
                                          dŒæ dt = d œÉ(t)2 /dt
                                                        
                          d             2
                                                                                                        (31)
                               0  s(Œæ)
                                        g(t)2 /s(t)2         =
                                                         2 œÉÃá(t) œÉ(t)                                   (32)
                                                         p
                                             g(t)/s(t) =    2 œÉÃá(t) œÉ(t)                                (33)
                                                              p
                                                  g(t) = s(t) 2 œÉÃá(t) œÉ(t).                             (34)

Finally, substitute f (Eq. 28) and g (Eq. 34) into the ODE of Eq. 24:

           dx = [f (t)] x ‚àí 12 [g(t)]2 ‚àáx log p x/s(t); œÉ(t) dt
                                                                   
                                                                                                        (35)
                                          h                  i2                       
                                                p
                        sÃá(t)/s(t) x ‚àí 12 s(t) 2 œÉÃá(t) œÉ(t) ‚àáx log p x/s(t); œÉ(t) dt
                                                                                   
                 =                                                                                      (36)
                                          h                 i                      
                        sÃá(t)/s(t) x ‚àí 12 2 s(t)2 œÉÃá(t) œÉ(t) ‚àáx log p x/s(t); œÉ(t) dt
                                                                                
                 =                                                                                      (37)
                                                                      
                       sÃá(t)                                  x
                 =           x ‚àí s(t)2 œÉÃá(t) œÉ(t) ‚àáx log p        ; œÉ(t)   dt.                          (38)
                       s(t)                                  s(t)

Thus we have obtained Eq. 4 in the main paper, and Eq. 1 is recovered by setting s(t) = 1:
                                                                
                            dx = ‚àíœÉÃá(t) œÉ(t) ‚àáx log p x; œÉ(t) dt.                                       (39)

Our formulation (Eq. 4) highlights the fact that every realization of the probability flow ODE is simply
a reparameterization of the same canonical ODE; changing œÉ(t) corresponds to reparameterizing t,
whereas changing s(t) corresponds to reparameterizing x.

B.3   Denoising score matching (Eq. 2 and Eq. 3)

For the sake of completeness, we derive the connection between score matching and denoising for a
finite dataset. For a more general treatment and further background on the topic, see Hyv√§rinen [22]
and Vincent [54].
Let us assume that our training set consists of a finite number of samples {y 1 , . . . , y Y }. This implies
pdata (x) is represented by a mixture of Dirac delta distributions:
                                                       Y
                                                    1 X           
                                        pdata (x) =       Œ¥ x ‚àí yi ,                                    (40)
                                                    Y i=1


                                                         23
which allows us to also express p(x; œÉ) in closed form based on Eq. 20:
                  p(x; œÉ) = pdata ‚àó N 0, œÉ(t)2 I
                                                       
                                                                                                        (41)
                                 Z
                                      pdata (x0 ) N x; x0 , œÉ 2 I dx0
                                                                 
                            =                                                                           (42)
                                   Rd
                                 Z " X       Y
                                                            #
                                        1
                                                Œ¥ x0 ‚àí y i N x; x0 , œÉ 2 I dx0
                                                                          
                            =                                                                           (43)
                                   Rd Y i=1
                                      Y Z
                                  1 X
                                               N x; x0 , œÉ 2 I Œ¥ x0 ‚àí y i dx0
                                                                        
                            =                                                                           (44)
                                 Y i=1 Rd
                                       Y
                                    1 X
                                          N x; y i , œÉ 2 I .
                                                          
                              =                                                                         (45)
                                    Y i=1

Let us now consider the denoising score matching loss of Eq. 2. By expanding the expectations, we
can rewrite the formula as an integral over the noisy samples x:
                                                                                       2
                 L(D; œÉ)     = Ey‚àºpdata En‚àºN (0,œÉ2 I) D(y + n; œÉ) ‚àí y                  2
                                                                                                        (46)
                                                                                  2
                             = Ey‚àºpdata Ex‚àºN (y,œÉ2 I) D(x; œÉ) ‚àí y                 2
                                                                                                        (47)
                                        Z
                                                                                           2
                             = Ey‚àºpdata    N (x; y, œÉ 2 I) D(x; œÉ) ‚àí y                     2
                                                                                                dx      (48)
                                             Rd
                                    Y Z
                               1 X                                          2
                             =             N (x; y i , œÉ 2 I) D(x; œÉ) ‚àí y i 2 dx                        (49)
                               Y i=1 Rd
                               Z        Y
                                     1 X                                    2
                             =             N (x; y i , œÉ 2 I) D(x; œÉ) ‚àí y i 2 dx.                       (50)
                                R d Y  i=1
                                    |                    {z                 }
                                                           =: L(D;x,œÉ)


Eq. 50 means that we can minimize L(D; œÉ) by minimizing L(D; x, œÉ) independently for each x:
                                 D(x; œÉ) = arg minD(x;œÉ) L(D; x, œÉ).                                    (51)
This is a convex optimization problem; its solution is uniquely identified by setting the gradient w.r.t.
D(x; œÉ) to zero:
                                    h             i
                    0 = ‚àáD(x;œÉ) L(D; x, œÉ)                                                         (52)
                                    "      Y
                                                                                    #
                                      1 X                                         2
                    0 = ‚àáD(x;œÉ)               N (x; y i , œÉ 2 I) D(x; œÉ) ‚àí y i 2                   (53)
                                      Y i=1
                             Y                                  h                           i
                             X                                                          2
                    0 =            N (x; y i , œÉ 2 I) ‚àáD(x;œÉ)       D(x; œÉ) ‚àí y i       2
                                                                                                        (54)
                             i=1
                             Y
                             X                       h                  i
                    0 =            N (x; y i , œÉ 2 I) 2 D(x; œÉ) ‚àí 2 y i                                 (55)
                             i=1
                             "   Y
                                                       #                 Y
                                 X                                       X
                                                  2
                    0 =                N (x; y i , œÉ I) D(x; œÉ) ‚àí              N (x; y i , œÉ 2 I) y i   (56)
                                 i=1                                     i=1
                                               2
                              P
                               i N (x; y i , œÉ I) y i
             D(x; œÉ)     =     P                 2
                                                      ,                                                 (57)
                                 i N (x; y i , œÉ I)

which gives a closed-form solution for the ideal denoiser D(x; œÉ). Note that Eq. 57 is feasible to
compute in practice for small datasets ‚Äî we show the results for CIFAR-10 in Figure 1b.


                                                      24
Next, let us consider the score of the distribution p(x; œÉ) defined in Eq. 45:
                                                   ‚àáx p(x; œÉ)
                         ‚àáx log p(x; œÉ)     =                                                        (58)
                                                    p(x; œÉ)
                                                      h P                         i
                                                   ‚àáx Y1 i N x; y i , œÉ 2 I
                                            =       h P                          i                  (59)
                                                      1                      2 I
                                                      Y    i N x;   y i ,  œÉ
                                                   P                      2
                                                                              
                                                     i ‚àáx N x; y i , œÉ I
                                            =       P                 2
                                                                             .                      (60)
                                                       i N x; y i , œÉ I

We can simplify the numerator of Eq. 60 further:
                                         "                               #
                          2
                                                  d
                                                 2 ‚àí2       kx ‚àí y i k22
           ‚àáx N x; y i , œÉ I = ‚àáx 2œÄœÉ                  exp                                           (61)
                                                               ‚àí2 œÉ 2
                                                     "                   #
                                              d
                                            2 ‚àí2            kx ‚àí y i k22
                                 = 2œÄœÉ            ‚àáx exp                                             (62)
                                                               ‚àí2 œÉ 2
                                      "                               #    "              #
                                               d
                                             2 ‚àí2        kx ‚àí y i k22        kx ‚àí y i k22
                                 =       2œÄœÉ       exp                  ‚àáx                           (63)
                                                           ‚àí2 œÉ 2              ‚àí2 œÉ 2
                                                           "              #
                                                             kx ‚àí y i k22
                                 = N x; y i , œÉ 2 I ‚àáx
                                                      
                                                                                                     (64)
                                                                ‚àí2 œÉ 2
                                                                
                                                   2
                                                       yi ‚àí x
                                 = N x; y i , œÉ I                   .                                (65)
                                                            œÉ2

Let us substitute the result back to Eq. 60:
                                               P                         2
                                                                             
                                                i ‚àáx N x; y i , œÉ I
                     ‚àáx log p(x; œÉ)     =       P                      2
                                                                                                    (66)
                                                  i N x; y i , œÉ I
                                               P                     2
                                                                         h yi ‚àíx i
                                                i N     x; y i ,  œÉ    I      œÉ2
                                        =         P                       2
                                                                                                    (67)
                                                       i N x; y i , œÉ I
                                                                                   !
                                                                       2
                                                P
                                                   i N x; y i , œÉ I y i
                                                                              ‚àí x œÉ2 .
                                                                                     
                                        =        P                       2 I
                                                                                                     (68)
                                                     i  N  x;    y i , œÉ

Notice that the fraction in Eq. 68 is identical to Eq. 57. We can thus equivalently write Eq. 68 as
                                ‚àáx log p(x; œÉ) = D(x; œÉ) ‚àí x /œÉ 2 ,
                                                                  
                                                                                                  (69)
which matches Eq. 3 in the main paper.

B.4   Evaluating our ODE in practice (Algorithm 1)

Let us consider x to be a scaled version of an original, non-scaled variable xÃÇ and substitute x = s(t) xÃÇ
into the score term that appears in our scaled ODE (Eq. 4):
                                                              
                                      ‚àáx log p x/s(t); œÉ(t)                                          (70)
                                                                         
                                  = ‚àá[s(t)xÃÇ] log p [s(t) xÃÇ]/s(t); œÉ(t)                             (71)
                                                            
                                  = ‚àás(t)xÃÇ log p xÃÇ; œÉ(t)                                           (72)
                                        1
                                                             
                                  = s(t) ‚àáxÃÇ log p xÃÇ; œÉ(t) .                                        (73)

We can further rewrite this with respect to D(¬∑) using Eq. 3:
                                                                           
                                                      1
                                                                      
                     ‚àáx log p x/s(t); œÉ(t) = s(t)œÉ(t)    2   D xÃÇ; œÉ(t) ‚àí xÃÇ .                       (74)


                                                     25
Let us now substitute Eq. 74 into Eq. 4, approximating the ideal denoiser D(¬∑) with our trained model
DŒ∏ (¬∑):
                      h                                  h                          ii
           dx = sÃá(t) x/s(t) ‚àí s(t)2 œÉÃá(t) œÉ(t) s(t)œÉ(t)     1
                                                                               
                                                                2   DŒ∏ xÃÇ; œÉ(t) ‚àí xÃÇ     dt      (75)
                      h                                     i
                        sÃá(t)    œÉÃá(t)s(t)              
                =       s(t) x ‚àí œÉ(t)        DŒ∏ xÃÇ; œÉ(t) ‚àí xÃÇ dt.                                (76)

Finally, backsubstitute xÃÇ = x/s(t):
                            h                                               i
                              sÃá(t)       œÉÃá(t)s(t)                  
                dx =          s(t)   x ‚àí     œÉ(t)     D Œ∏  [xÃÇ]; œÉ(t)  ‚àí [xÃÇ]   dt               (77)
                            h                                                        i
                              sÃá(t)       œÉÃá(t)s(t)                       
                       =      s(t) x ‚àí œÉ(t)           DŒ∏ [x/s(t)]; œÉ(t) ‚àí [x/s(t)] dt            (78)
                            h                                           œÉÃá(t) i
                              sÃá(t)       œÉÃá(t)s(t)
                       =      s(t)   x ‚àí     œÉ(t)   D Œ∏  x/s(t);   œÉ(t)  + œÉ(t) x dt             (79)
                            h                                                  i
                                 œÉÃá(t)   sÃá(t)         œÉÃá(t)s(t)
                       =         œÉ(t) + s(t) x ‚àí œÉ(t) DŒ∏ x/s(t); œÉ(t)               dt.          (80)

We can equivalenty write Eq. 80 as
                                                                        
                                œÉÃá(t) sÃá(t)      œÉÃá(t)s(t)       x
                   dx/dt =           +        x‚àí           DŒ∏        ; œÉ(t) ,                    (81)
                                œÉ(t) s(t)           œÉ(t)        s(t)
matching lines 4 and 7 of Algorithm 1.

B.5     Our SDE formulation (Eq. 6)

We derive the SDE of Eq. 6 by the following strategy:
                                                   
      ‚Ä¢ The desired marginal densities p x; œÉ(t) are convolutions of the data density pdata and an
        isotropic Gaussian density with standard deviation œÉ(t) (see Eq. 20). Hence, considered
        as a function of the time t, the density evolves according to a heat diffusion PDE with
        time-varying diffusivity. As a first step, we find this PDE.
      ‚Ä¢ We then use the Fokker‚ÄìPlanck equation to recover a family of SDEs for which the density
        evolves according to this PDE. Eq. 6 is obtained from a suitable parametrization of this
        family.

B.5.1    Generating the marginals by heat diffusion
We consider the time evolution of a probability density q(x, t). Our goal   is to find a PDE whose
solution with the initial value q(x, 0) := pdata (x) is q(x, t) = p x, œÉ(t) . That is, the PDE should
reproduce the marginals we postulate in Eq. 20.
The desired marginals are convolutions of pdata with isotropic normal distributions of time-varying
standard deviation œÉ(t), and as such, can be generated by the heat equation with time-varying
diffusivity Œ∫(t). The situation is most conveniently analyzed in the Fourier domain, where the
marginal densities are simply pointwise products of a Gaussian function and the transformed data
density. To find the diffusivity that induces the correct standard deviations, we first write down the
heat equation PDE:
                                       ‚àÇq(x, t)
                                                = Œ∫(t)‚àÜx q(x, t).                                 (82)
                                         ‚àÇt
The Fourier transformed counterpart of Eq. 82, where the transform is taken along the x-dimension,
is given by
                                 ‚àÇ qÃÇ(ŒΩ, t)
                                            = ‚àíŒ∫(t)|ŒΩ|2 qÃÇ(ŒΩ, t).                            (83)
                                     ‚àÇt
The target solution q(x, t) and its Fourier transform qÃÇ(ŒΩ, t) are given by Eq. 20:
                       q(x, t) = p x; œÉ(t) = pdata (x) ‚àó N 0, œÉ(t)2 I
                                                                             
                                                                                                 (84)
                                                                     
                       qÃÇ(ŒΩ, t) = pÃÇdata (ŒΩ) exp ‚àí 21 |ŒΩ|2 œÉ(t)2 .                               (85)


                                                   26
Differentiating the target solution along the time axis, we have
                   ‚àÇ qÃÇ(ŒΩ, t)                                                   
                                = ‚àíœÉÃá(t)œÉ(t) |ŒΩ|2 pÃÇdata (ŒΩ) exp ‚àí 12 |ŒΩ|2 œÉ(t)2                    (86)
                       ‚àÇt
                                = ‚àíœÉÃá(t)œÉ(t) |ŒΩ|2 qÃÇ(ŒΩ, t).                                         (87)

Eqs. 83 and 87 share the same left hand side. Equating them allows us to solve for Œ∫(t) that generates
the desired evolution:
                            ‚àíŒ∫(t)|ŒΩ|2 qÃÇ(ŒΩ, t) = ‚àíœÉÃá(t)œÉ(t) |ŒΩ|2 qÃÇ(ŒΩ, t)                           (88)
                                         Œ∫(t) = œÉÃá(t)œÉ(t).                                          (89)

To summarize, the desired marginal densities corresponding to noise levels œÉ(t) are generated by the
PDE
                                   ‚àÇq(x, t)
                                              = œÉÃá(t)œÉ(t)‚àÜx q(x, t)                             (90)
                                       ‚àÇt
from the initial density q(x, 0) = pdata (x).

B.5.2   Derivation of our SDE
Given an SDE
                                   dx = f (x, t) dt + g(x, t) dœât ,                                 (91)
the Fokker‚ÄìPlanck PDE describes the time evolution of its solution probability density r(x, t) as
               ‚àÇr(x, t)
                        = ‚àí‚àáx ¬∑ f (x, t) r(x, t) + 21 ‚àáx ‚àáx : D(x, t) r(x, t) ,
                                                                              
                                                                                             (92)
                 ‚àÇt
            P
where Dij = k g ik g jk is the diffusion tensor. We consider the special case g(x, t) = g(t) I of
x-independent white noise addition, whereby the equation simplifies to
                      ‚àÇr(x, t)                                  1
                                                                    g(t)2 ‚àÜx r(x, t).
                                                       
                               = ‚àí‚àáx ¬∑ f (x, t) r(x, t) +       2                                   (93)
                        ‚àÇt

We are seeking an SDE whose solution density is described by the PDE in Eq. 90. Setting r(x, t) =
q(x, t) and equating Eqs. 93 and 90, we find the sufficient condition that the SDE must satisfy
      ‚àí‚àáx ¬∑ f (x, t) q(x, t) + 21 g(t)2 ‚àÜx q(x, t) = œÉÃá(t) œÉ(t) ‚àÜx q(x, t)
                             
                                                                                                (94)
                                                                                
                                                              1     2
                                                   
                              ‚àáx ¬∑ f (x, t) q(x, t) =         2 g(t) ‚àí œÉÃá(t) œÉ(t) ‚àÜx q(x, t). (95)


Any choice of functions f (x, t) and g(t) satisfying this equation constitute a sought after SDE. Let
us now find a specific family of such solutions. The key idea is given by the identity ‚àáx ¬∑ ‚àáx = ‚àÜx .
Indeed, if we set f (x, t) q(x, t) = œÖ(t) ‚àáx q(x, t) for any choice of œÖ(t), the term ‚àÜx q(x, t) appears
on both sides and cancels out:
                                                                        
                                                    1      2
                                          
                    ‚àáx ¬∑ œÖ(t) ‚àáx q(x, t) =          2 g(t)   ‚àí œÉÃá(t) œÉ(t)  ‚àÜx q(x, t)               (96)
                                                                        
                                                    1      2
                            œÖ(t) ‚àÜx q(x, t) =       2 g(t) ‚àí œÉÃá(t) œÉ(t) ‚àÜx q(x, t)                  (97)
                                      œÖ(t)   =    1
                                                  2   g(t)2 ‚àí œÉÃá(t) œÉ(t).                           (98)

The stated f (x, t) is in fact proportional to the score function, as the formula matches the gradient of
the logarithm of the density:
                                          ‚àáx q(x, t)
                        f (x, t)   = œÖ(t)                                                           (99)
                                            q(x, t)
                                   = œÖ(t) ‚àáx log q(x, t)                                           (100)
                                                           
                                       1      2
                                   =   2 g(t)   ‚àí œÉÃá(t) œÉ(t)  ‚àáx log q(x, t).                      (101)


                                                   27
Substituting this back into Eq. 91 and writing p(x; œÉ(t)) in place of q(x, t), we recover a family of
SDEs whose solution densities have the desired marginals with noise levels œÉ(t) for any choice of
g(t):                                        
                  dx = 12 g(t)2 ‚àí œÉÃá(t) œÉ(t) ‚àáx log p x; œÉ(t) dt + g(t) dœât .
                                                                 
                                                                                               (102)

The free parameter g(t) effectively specifies the rate of noise replacement at any given time instance.
The special case choice of g(t) = 0 corresponds to the probability flow ODE. The parametrization
by g(t) p
        is not particularly intuitive, however. To obtain a more interpretable parametrization, we set
g(t) = 2 Œ≤(t) œÉ(t), which yields the (forward) SDE of Eq. 6 in the main paper:
                                                                                  p
  dx+ = ‚àíœÉÃá(t)œÉ(t)‚àáx log p x; œÉ(t) dt + Œ≤(t)œÉ(t)2 ‚àáx log p x; œÉ(t) dt + 2Œ≤(t)œÉ(t) dœât .
                                                                          
                                                                                                 (103)
The noise replacement is now proportional to the standard deviation œÉ(t) of the noise, with the
proportionality factor Œ≤(t). Indeed,
                                      expanding
                                                  the score function in the middle term according
to Eq. 3 yields Œ≤(t) D x; œÉ(t) ‚àí x dt, which changes x proportionally to the negative noise
component; the stochastic term injects new noise at the same rate. Intuitively, scaling the magnitude
of Langevin exploration according to the current noise standard deviation is a reasonable baseline, as
the data manifold is effectively ‚Äúspread out‚Äù by this amount due to the blurring of the density.
The reverse SDE used in denoising diffusion is simply obtained by applying the time reversal formula
of Anderson [1] (as stated in Eq. 6 of Song et al. [49]) on Eq. 103; the entire effect of the reversal is a
change of sign in the middle term.
The scaled generalization of the SDE can be derived using a similar approach as with the ODE
previously. As such, the derivation is omitted here.

B.6   Our preconditioning and training (Eq. 8)

Following Eq. 2, the denoising score matching loss for a given denoiser DŒ∏ on a given noise level œÉ
is given by
                                                                            2
                    L(DŒ∏ ; œÉ) = Ey‚àºpdata En‚àºN (0,œÉ2 I) DŒ∏ (y + n; œÉ) ‚àí y 2 .                  (104)

We obtain overall training loss by taking a weighted expectation of L(DŒ∏ ; œÉ) over the noise levels:
                                                 
           L(DŒ∏ ) = EœÉ‚àºptrain Œª(œÉ) L(DŒ∏ ; œÉ)                                                   (105)
                                    h                                                  i
                                                                                     2
                      = EœÉ‚àºptrain Œª(œÉ) Ey‚àºpdata En‚àºN (0,œÉ2 I) DŒ∏ (y + n; œÉ) ‚àí y 2              (106)
                                                        h                              i
                                                                                     2
                      = EœÉ‚àºptrain Ey‚àºpdata En‚àºN (0,œÉ2 I) Œª(œÉ) DŒ∏ (y + n; œÉ) ‚àí y 2              (107)
                                 h                             i
                                                             2
                      = EœÉ,y,n Œª(œÉ) DŒ∏ (y + n; œÉ) ‚àí y 2 ,                                      (108)

where the noise levels are distributed according to œÉ ‚àº ptrain and weighted by Œª(œÉ).
Using our definition of DŒ∏ (¬∑) from Eq. 7, we can further rewrite L(DŒ∏ ) as
                   h                                                                i
                                                                                 2
            EœÉ,y,n Œª(œÉ) cskip (œÉ)(y+n) + cout (œÉ)FŒ∏ cin (œÉ)(y+n); cnoise (œÉ) ‚àí y 2                        (109)
                   h                                                               2i
       = EœÉ,y,n Œª(œÉ) cout (œÉ)FŒ∏ cin (œÉ)(y+n); cnoise (œÉ) ‚àí y ‚àí cskip (œÉ)(y + n) 2                         (110)
                   h                                                                                  i
                                                                                                  2
       = EœÉ,y,n Œª(œÉ)cout (œÉ)2 FŒ∏ cin (œÉ)(y+n); cnoise (œÉ) ‚àí cout1(œÉ) y ‚àí cskip (œÉ)(y+n)
                                                                                       
                                                                                                  2
                                                                                                          (111)
                   h                                                      i
                                                                       2
       = EœÉ,y,n w(œÉ) FŒ∏ cin (œÉ)(y+n); cnoise (œÉ) ‚àí Ftarget (y, n; œÉ) 2 ,                                  (112)
which matches Eq. 8 and corresponds to traditional supervised training of FŒ∏ using standard L2 loss
with effective weight w(¬∑) and target Ftarget (¬∑) given by
        w(œÉ) = Œª(œÉ) cout (œÉ)2 and Ftarget (y, n; œÉ) = cout1(œÉ) y ‚àí cskip (œÉ)(y + n) ,
                                                                                     
                                                                                             (113)

We can now derive formulas for cin (œÉ), cout (œÉ), cskip (œÉ), and Œª(œÉ) from first principles, shown in the
‚ÄúOurs‚Äù column of Table 1.


                                                    28
First, we require the training inputs of FŒ∏ (¬∑) to have unit variance:
                                                      
                            Vary,n cin (œÉ)(y + n) = 1                                                  (114)
                            cin (œÉ)2 Vary,n y + n = 1
                                                      
                                                                                                       (115)
                                  cin (œÉ)2 œÉdata
                                            2
                                                 + œÉ2
                                                       
                                                         = 1                                           (116)
                                                              q          2 .
                                                 cin (œÉ) = 1       œÉ 2 + œÉdata                         (117)

Second, we require the effective training target Ftarget to have unit variance:
                                               
                       Vary,n Ftarget (y, n; œÉ) = 1                                                    (118)
                 h                             i
      Vary,n cout1(œÉ) y ‚àí cskip (œÉ)(y + n)        = 1                                                  (119)
             1
                                               
        cout (œÉ)2 Vary,n y ‚àí cskip (œÉ)(y + n)     = 1                                                  (120)
                                                2
                                                                                      
                                        cout (œÉ) = Vary,n y ‚àí cskip (œÉ)(y + n)                         (121)
                                                                h                               i
                                        cout (œÉ)2 = Vary,n 1 ‚àí cskip (œÉ) y + cskip (œÉ) n
                                                                              
                                                                                                       (122)
                                                                      2 2
                                        cout (œÉ)2 = 1 ‚àí cskip (œÉ) œÉdata      + cskip (œÉ)2 œÉ 2 .        (123)

Third, we select cskip (œÉ) to minimize cout (œÉ), so that the errors of FŒ∏ are amplified as little as possible:

                                    cskip (œÉ) = arg mincskip (œÉ) cout (œÉ).                             (124)
Since cout (œÉ) ‚â• 0, we can equivalently write
                                    cskip (œÉ) = arg mincskip (œÉ) cout (œÉ)2 .                           (125)
This is a convex optimization problem; its solution is uniquely identified by setting the derivative
w.r.t. cskip (œÉ) to zero:
                      0 = d cout (œÉ)2 /dcskip (œÉ)
                                      
                                                                                               (126)
                           h                  2 2                  i
                      0 = d 1 ‚àí cskip (œÉ) œÉdata + cskip (œÉ)2 œÉ 2 /dcskip (œÉ)                   (127)
                                   h                  i
                           2                        2
                                 d 1 ‚àí cskip (œÉ) /dcskip (œÉ) + œÉ 2 d cskip (œÉ)2 /dcskip (œÉ)
                                                                             
                      0 = œÉdata                                                                (128)
                           2
                                  2 cskip (œÉ) ‚àí 2 + œÉ 2 2 cskip (œÉ)
                                                                
                      0 = œÉdata                                                                (129)
                             2       2                  2
                                        
                      0 = œÉ + œÉdata cskip (œÉ) ‚àí œÉdata                                          (130)
                           2         2      2
                                               
              cskip (œÉ) = œÉdata / œÉ + œÉdata .                                                  (131)

We can now substitute Eq. 131 into Eq. 123 to complete the formula for cout (œÉ):
                                                 2 2                   2
                cout (œÉ)2 = 1 ‚àí cskip (œÉ)            œÉdata + cskip (œÉ) œÉ 2
                                                                
                                                                                                       (132)
                                                      2                         2
                                             œÉ2                           œÉ2
                                                                    
                cout (œÉ)2 =       1 ‚àí 2 data2                   2
                                                             œÉdata  + 2 data2        œÉ2                (133)
                                         œÉ + œÉdata                      œÉ + œÉdata
                                 2            2  2                2
                        2          œÉ œÉdata                œÉdata œÉ
                cout (œÉ) =                 2       + 2            2                                    (134)
                                 œÉ 2 + œÉdata            œÉ + œÉdata
                                            2               2
                                 œÉ 2 œÉdata + œÉdata  2
                                                          œÉ
                cout (œÉ)2 =                          2                                                (135)
                                          2
                                        œÉ + œÉdata2
                                                             
                        2       (œÉ ¬∑ œÉdata )2 œÉ 2 + œÉdata2
                cout (œÉ) =                          2                                                 (136)
                                                2
                                        œÉ 2 + œÉdata
                                    (œÉ ¬∑ œÉdata )2
                   cout (œÉ)2    =             2                                                        (137)
                                    œÉ 2 + œÉdata
                                              q         2 .
                     cout (œÉ)   =   œÉ ¬∑ œÉdata     œÉ 2 + œÉdata                                          (138)


                                                      29
Fourth, we require the effective weight w(œÉ) to be uniform across noise levels:
                                    w(œÉ)      =   1                                               (139)
                                         2
                            Œª(œÉ) cout (œÉ)     =   1                                               (140)
                                     Œª(œÉ)   1/cout (œÉ)2
                                              =                                                   (141)
                                                               2
                                                   œÉ ¬∑ œÉdata
                                     Œª(œÉ) = 1 p             2
                                                                                                  (142)
                                                    œÉ 2 + œÉdata
                                               (œÉ ¬∑ œÉdata )2
                                                             
                                     Œª(œÉ) = 1            2                                        (143)
                                                 œÉ 2 + œÉdata
                                     Œª(œÉ) = œÉ + œÉdata /(œÉ ¬∑ œÉdata )2 .
                                               2      2
                                                         
                                                                                                  (144)

We follow previous work and initialize the output layer weights to zero. Consequently, upon
initialization FŒ∏ (¬∑) = 0 and the expected value of the loss at each noise level is 1. This can be seen
by substituting the choices of Œª(œÉ) and cskip (œÉ) into Eq. 109, considered at a fixed œÉ:
                          h                                                                 i
                                                                                         2
                    Ey,n Œª(œÉ) cskip (œÉ)(y+n) + cout (œÉ)FŒ∏ cin (œÉ)(y+n); cnoise (œÉ) ‚àí y 2          (145)
                           2        2            2                      2 
                            œÉ + œÉdata           œÉdata
               = Ey,n                                 2   (y+n)    ‚àí  y                           (146)
                            (œÉ ¬∑ œÉdata )2 œÉ 2 + œÉdata                    2
                           2        2        2                 2
                            œÉ + œÉdata       œÉdata n ‚àí œÉ2 y
               = Ey,n                                   2                                         (147)
                            (œÉ ¬∑ œÉdata )2     œÉ 2 + œÉdata       2
                                                                 2
                                 1         œÉdata          œÉ
               = Ey,n 2             2            n‚àí          y                                    (148)
                            œÉ + œÉdata        œÉ          œÉdata 2
                                        2
                                                             œÉ2
                                                                                    
                          1               œÉdata
               =             2   E y,n          hn, ni   +    2   hy, yi ‚àí   2hy, ni              (149)
                     œÉ 2 + œÉdata           œÉ2               œÉdata
                                  2
                                                        œÉ2
                                                                                      
                          1       œÉdata
               =             2            Var(n)    +    2   Var(y)   ‚àí2   Cov(y,  n)             (150)
                     œÉ 2 + œÉdata    œÉ 2 | {z } œÉdata         | {z }        | {z }
                                       =œÉ 2              2
                                                       =œÉdata        =0

              =   1                                                                               (151)


C     Reframing previous methods in our framework

In this section, we derive the formulas shown in Table 1 for previous methods, discuss the corre-
sponding original samplers and pre-trained models, and detail the practical considerations associated
with using them in our framework.
In practice, the original implementations of these methods differ considerably in terms of the
definitions of model inputs and outputs, dynamic range of image data, scaling of x, and interpretation
of œÉ. We eliminate this variation by standardizing on a unified setup where the model always matches
our definition of FŒ∏ , image data is always represented in the continuous range [‚àí1, 1], and the details
of x and œÉ are always in agreement with Eq. 4.
We minimize the accumulation of floating point round-off errors by always executing Algorithms 1
and 2 at double precision (float64). However, we still execute the network FŒ∏ (¬∑) at single precision
(float32) to minimize runtime and remain faithful to previous work in terms of network architecture.

C.1     Variance preserving formulation

C.1.1    VP sampling
Song et al. [49] define the VP SDE (Eq. 32 in [49]) as
                                                    q
             dx = ‚àí 21 Œ≤min + t Œ≤max ‚àí Œ≤min x dt + Œ≤min + t Œ≤max ‚àí Œ≤min dœât ,
                                                                       
                                                                                                  (152)


                                                  30
which matches Eq. 10 with the following choices for f and g:
                                      p
          f (t) = ‚àí 12 Œ≤(t), g(t) = Œ≤(t), and Œ≤(t) = Œ≤max ‚àí Œ≤min t + Œ≤min .
                                                                
                                                                                                  (153)

Let Œ±(t) denote the integral of Œ≤(t):
                                          Z       t
                            Œ±(t)    =                 Œ≤(Œæ) dŒæ                                     (154)
                                              0
                                          Z th                                i
                                                                   
                                    =                   Œ≤max ‚àí Œ≤min Œæ + Œ≤min dŒæ                   (155)
                                              0
                                          1
                                                      Œ≤max ‚àí Œ≤min t2 + Œ≤min t
                                                                 
                                    =     2                                                       (156)
                                          1             2
                                    =     2   Œ≤d t + Œ≤min t,                                      (157)
where Œ≤d = Œ≤max ‚àí Œ≤min . We can now obtain the formula for œÉ(t) by substituting Eq. 153 into Eq. 12:
                                          v
                                          uZ t          2
                                          u         g(Œæ)
                               œÉ(t) = t                 2 dŒæ                                (158)
                                              0     s(Œæ)
                                          v
                                          uZ t p            2
                                          u             Œ≤(Œæ)
                                     =    t         ‚àö        2 dŒæ                           (159)
                                              0     1/ eŒ±(Œæ)
                                          sZ
                                                t
                                                     Œ≤(Œæ)
                                     =                 Œ±(Œæ)
                                                            dŒæ                                (160)
                                              0 1/e
                                          s
                                             Z t
                                     =            Œ±Ãá(Œæ) eŒ±(Œæ) dŒæ                              (161)
                                                            0
                                                       p
                                          =             eŒ±(t) ‚àí eŒ±(0)                             (162)
                                                       q
                                                          1     2
                                          =             e 2 Œ≤d t +Œ≤min t ‚àí 1,                     (163)
which matches the ‚ÄúSchedule‚Äù row of Table 1. Similarly for s(t):
                                           Z t               
                                                         
                            s(t) = exp              f (Œæ) dŒæ                                      (164)
                                                0
                                           Z t                    
                                                    1         
                                  = exp              ‚àí 2 Œ≤(Œæ) dŒæ                                  (165)
                                                0
                                                  Z t           
                                                 1
                                  = exp ‚àí 2               Œ≤(Œæ) dŒæ                                 (166)
                                                      0
                                  = exp ‚àí 12 Œ±(t)
                                                        
                                                                                                  (167)
                                         p
                                  = 1/ eŒ±(t)                                                      (168)
                                         p
                                              1    2
                                  = 1/ e 2 Œ≤d t +Œ≤min t ,                                         (169)
which matches the ‚ÄúScaling‚Äù row of Table 1. We can equivalently write Eq. 169 in a slightly simpler
form by utilizing Eq. 163:                    p
                                     s(t) = 1/ œÉ(t)2 + 1.                                     (170)
Song et al. [49] choose to distribute the sampling time steps {t0 , . . . , tN ‚àí1 } at uniform intervals
within [s , 1]. This corresponds to setting
                                                                  i
                                        ti<N = 1 +              N ‚àí1 (s   ‚àí 1),                  (171)
which matches the ‚ÄúTime steps‚Äù row of Table 1.
Finally, Song et al. [49] set Œ≤min = 0.1, Œ≤max = 20, and s = 10‚àí3 (Appendix C in [49]), and choose
to represent images in the range [‚àí1, 1]. These choices are readily compatible with our formulation
and are reflected by the ‚ÄúParameters‚Äù section of Table 1.


                                                            31
C.1.2       VP preconditioning
In the VP case, Song et al. [49] approximate the score of pt (x) of Eq. 13 as1
                                                  1
                                                                      
                             ‚àáx log pt (x) ‚âà ‚àí œÉÃÑ(t) FŒ∏ x; (M ‚àí1)t ,                                                   (172)
                                              |           {z          }
                                                                   score(x;FŒ∏ ,t)

where M = 1000, FŒ∏ denotes the network, and œÉÃÑ(t) corresponds to the standard deviation of the
perturbation kernel of Eq. 11.
Let us expand the definitions of pt (x) and œÉÃÑ(t) from Eqs. 20 and 11, respectively, and substitute
x = s(t)xÃÇ to obtain the corresponding formula with respect to the non-scaled variable xÃÇ:
                                                              1
                                                                                 
                       ‚àáx log p x/s(t); œÉ(t)         ‚âà ‚àí [s(t)œÉ(t)] FŒ∏ x; (M ‚àí1)t            (173)
                                                             1
                                                                                        
             ‚àá[s(t)xÃÇ] log p [s(t) xÃÇ]/s(t); œÉ(t) ‚âà ‚àí s(t)œÉ(t)     FŒ∏ [s(t) xÃÇ]; (M ‚àí1)t     (174)
                            1                                1
                                                                                      
                           s(t) ‚àáxÃÇ log p xÃÇ; œÉ(t)   ‚âà ‚àí s(t)œÉ(t) FŒ∏ s(t) xÃÇ; (M ‚àí1)t        (175)
                                                           1
                                                                                   
                                ‚àáxÃÇ log p xÃÇ; œÉ(t) ‚âà ‚àí œÉ(t)    FŒ∏ s(t) xÃÇ; (M ‚àí1)t .         (176)

We can now replace the left-hand side with Eq. 3 and expand the definition of s(t) from Eq. 170:
         h                          i
            D xÃÇ; œÉ(t) ‚àí xÃÇ /œÉ(t)2               1
                                                                        
                                         ‚âà ‚àí œÉ(t)   FŒ∏ s(t) xÃÇ; (M ‚àí1)t                      (177)
                                                                            
                           D xÃÇ; œÉ(t) ‚âà xÃÇ ‚àí œÉ(t) FŒ∏ s(t) xÃÇ; (M ‚àí1)t                        (178)
                                                                                   
                           D xÃÇ; œÉ(t) ‚âà xÃÇ ‚àí œÉ(t) FŒ∏ ‚àö 1 2
                                      
                                                                         xÃÇ; (M ‚àí1)t ,       (179)
                                                                                    œÉ(t) +1

which can be further expressed in terms of œÉ by replacing œÉ(t) ‚Üí œÉ and t ‚Üí œÉ ‚àí1 (œÉ):
                                                                        
                       D(xÃÇ; œÉ) ‚âà xÃÇ ‚àí œÉ FŒ∏ ‚àöœÉ12 +1 xÃÇ; (M ‚àí1) œÉ ‚àí1 (œÉ) .                                              (180)

We adopt the right-hand side of Eq. 180 as the definition of DŒ∏ , obtaining
                                                                             
                                1 ¬∑ xÃÇ ‚àí œÉ ¬∑ FŒ∏ ‚àöœÉ12 +1 ¬∑ xÃÇ; (M ‚àí1) œÉ ‚àí1 (œÉ) ,
                  DŒ∏ (xÃÇ; œÉ) = |{z}                                                                                    (181)
                                       |{z}                    |       {z   }
                                cskip   cout
                                                  | {z }
                                                                                        cnoise
                                                                   cin

where cskip , cout , cin , and cnoise match the ‚ÄúNetwork and preconditioning‚Äù section of Table 1.

C.1.3       VP training
Song et al. [49] define their training loss as2
                                             h                                                                i
                                                                                                         2
             Et‚àºU (t ,1),y‚àºpdata ,nÃÑ‚àºN (0,I) œÉÃÑ(t) score s(t) y + œÉÃÑ(t) nÃÑ; FŒ∏ , t + nÃÑ                  2
                                                                                                                  ,    (182)

where the definition of score(¬∑) is the same as in Eq. 172. Let us simplify the formula by substituting
œÉÃÑ(t) = s(t)œÉ(t) and nÃÑ = n/œÉ(t), where n ‚àº N (0, œÉ(t)2 I):
                      h                                                            i
                                                                                2
               Et,y,nÃÑ s(t)œÉ(t) score s(t) y + [s(t)œÉ(t)] nÃÑ; FŒ∏ , t + nÃÑ 2                      (183)
                      h                                                                       i
                                                                                           2
           = Et,y,n s(t)œÉ(t) score s(t) y + s(t)œÉ(t) [n/œÉ(t)]; FŒ∏ , t + [n/œÉ(t)] 2               (184)
                      h                                                        i
                                                                            2
           = Et,y,n s(t)œÉ(t) score s(t) (y + n); FŒ∏ , t + n/œÉ(t) 2 .                             (185)

We can express score(¬∑) in terms of DŒ∏ (¬∑) by combining Eqs. 172, 170, and 74:
                                                                        
                                                  1
                                                                   
                     score s(t) x; FŒ∏ , t = s(t)œÉ(t)  2   DŒ∏ x; œÉ(t)  ‚àí x  .                                           (186)
   1
       https://github.com/yang-song/score_sde_pytorch/blob/1618ddea340f3e4a2ed7852a0694a809775cf8d0/models/utils.py#L144
   2
       https://github.com/yang-song/score_sde_pytorch/blob/1618ddea340f3e4a2ed7852a0694a809775cf8d0/losses.py#L73




                                                              32
Substituting this back into Eq. 185 gives
                               h   h                                    i                                                          i
                                       1
                                                                                                                      1         2
                          s(t)œÉ(t) s(t)œÉ(t)
                      Et,y,n                2   DŒ∏ y + n; œÉ(t) ‚àí (y + n) +                                            œÉ(t)   n   2
                                                                                                                                         (187)
                        h                                             i
                            1
                                                                1    2
                = Et,y,n œÉ(t)    DŒ∏ y + n; œÉ(t) ‚àí (y + n) + œÉ(t)    n 2                                                                  (188)
                        h                                i
                           1
                                                      2
                = Et,y,n œÉ(t)2   DŒ∏ y + n; œÉ(t) ‚àí y 2 .                                                                                  (189)


We can further express this in terms of œÉ by replacing œÉ(t) ‚Üí œÉ and t ‚Üí œÉ ‚àí1 (œÉ):
                                                      h                                                       i
                                                                                                          2
                               EœÉ‚àí1 (œÉ)‚àºU (t ,1) Ey,n œÉ12 DŒ∏ y + n; œÉ ‚àí y
                                                                      
                                                                                                          2
                                                                                                                  ,                      (190)
                               |      {z        }       |{z}
                                       ptrain                         Œª


which matches Eq. 108 with the choices for ptrain and Œª shown in the ‚ÄúTraining‚Äù section of Table 1.


C.1.4       VP practical considerations

The pre-trained VP model that we use on CIFAR-10 corresponds to the ‚ÄúDDPM++ cont. (VP)‚Äù
checkpoint3 provided by Song et al. [49]. It contains
                                                   a total of 62 million trainable parameters and
supports a continuous range of noise levels œÉ ‚àà œÉ(t ), œÉ(1) ‚âà [0.001, 152], i.e., wider than our
preferred sampling range [0.002, 80]. We import the model directly as FŒ∏ (¬∑) and run Algorithms 1
and 2 using the definitions in Table 1.
In Figure 2a, the differences between the original sampler (blue) and our reimplementation (orange)
are explained by oversights in the implementation of Song et al. [49], also noted by Jolicoeur-
Martineau et al. [24] (Appendix D in [24]). First, the original sampler employs an incorrect multiplier4
in the Euler step: it multiplies dx/dt by ‚àí1/N instead of (s ‚àí 1)/(N ‚àí 1). Second, it either
overshoots or undershoots on the last step by going from tN ‚àí1 = s to tN = s ‚àí 1/N , where tN < 0
when N < 1000. In practice, this means that the generated images contain noticeable noise that
becomes quite severe with, e.g., N = 128. Our formulation avoids these issues, because the step
sizes in Algorithm 1 are computed consistently from {ti } and tN = 0.


C.2      Variance exploding formulation

C.2.1       VE sampling in theory

Song et al. [49] define the VE SDE (Eq. 30 in [49]) as
                                                                     t r
                                                               œÉmax                       œÉmax
                                        dx = œÉmin                            2 log             dœât ,                                     (191)
                                                               œÉmin                       œÉmin

which matches Eq. 10 with
                                                            p
                        f (t) = 0,      g(t) = œÉmin              2 log œÉd œÉdt ,           and   œÉd = œÉmax /œÉmin .                        (192)

The VE formulation does not employ scaling, which can be easily seen from Eq. 12:
                                     Z       t           
                                                                            Z       t    
                                                                                                  
                      s(t) = exp                      f (Œæ) dŒæ       = exp                 0 dŒæ       = exp(0) = 1.                      (193)
                                          0                                       0


   3
       vp/cifar10_ddpmpp_continuous/checkpoint_8.pth, https://drive.google.com/drive/folders/1xYjVMx10N9ivQQBIsEoXEeu9nvSGTBrC
   4
       https://github.com/yang-song/score_sde_pytorch/blob/1618ddea340f3e4a2ed7852a0694a809775cf8d0/sampling.py#L182




                                                                      33
Substituting Eq. 192 into Eq. 12 suggests the following form for œÉ(t):
                                      v
                                      uZ t         2
                                      u        g(Œæ)
                           œÉ(t) =     t           2 dŒæ                                                               (194)
                                           0   s(Œæ)
                                                   ‚àö
                                      v
                                      uZ t                      2
                                      u        œÉmin 2 log œÉd œÉdŒæ
                                  =   t                 2         dŒæ                                                 (195)
                                           0            1
                                      s
                                        Z t
                                                            
                                  =            2
                                             œÉmin   2 log œÉd œÉd2Œæ dŒæ                                                   (196)
                                                      0
                                                        s
                                                         Z th
                                                                               i h         Œæ i
                                            =    œÉmin              log œÉd2            œÉd2          dŒæ                  (197)
                                                            0
                                                        q         t           0
                                            =    œÉmin       œÉd2        ‚àí œÉd2                                           (198)
                                                  p
                                            = œÉmin œÉd2t ‚àí 1.                                                           (199)

Eq. 199 is consistent with the perturbation kernel reported by Song et al. (Eq. 29 in [49]). However,
                                                                                  t
we note that this does not fulfill their intended definition of œÉ(t) = œÉmin œÉœÉmax
                                                                              min
                                                                                     (Appendix C in [49]).

C.2.2       VE sampling in practice
The original implementation5 of Song et al. [49] uses reverse diffusion predictor6 to integrate
discretized reverse probability flow7 of discretized VE SDE8 . Put together, these yield the following
update rule for xi+1 :
                             xi+1 = xi + 21 œÉÃÑi2 ‚àí œÉÃÑi+1
                                                      2
                                                         
                                                           ‚àáx log pÃÑi (x),                        (200)
where                                         1‚àíi/(N ‚àí1)
                                          œÉmax
                         œÉÃÑi<N = œÉmin                        and œÉÃÑN = 0.                         (201)
                                          œÉmin
Interestingly, Eq. 200 is identical to the Euler iteration of our ODE with the following choices:
                                                     ‚àö
                               s(t) = 1, œÉ(t) = t, and ti = œÉÃÑi2 .                              (202)

These formulas match the ‚ÄúSampling‚Äù section of Table 1, and their correctness can be verified by
substituting them into line 5 of Algorithm 1:
               xi+1      = xi + (ti+1 ‚àí ti ) di                                                                        (203)
                                                                                           
                                                  œÉÃá(t) sÃá(t)         œÉÃá(t)s(t)      x
                         = xi + (ti+1 ‚àí ti )            +        x‚àí             D        ; œÉ(t)                        (204)
                                                  œÉ(t) s(t)              œÉ(t)       s(t)
                                                                             
                                               œÉÃá(t)       œÉÃá(t)            
                         = xi + (ti+1 ‚àí ti )          x‚àí         D x; œÉ(t)                                             (205)
                                               œÉ(t)        œÉ(t)
                                                                                   
                                                                                     2
                                                                       
                         = xi ‚àí (ti+1 ‚àí ti ) œÉÃá(t) œÉ(t) D x; œÉ(t) ‚àí x œÉ(t)                                             (206)
                                                                           
                         = xi ‚àí (ti+1 ‚àí ti ) œÉÃá(t) œÉ(t) ‚àáx log p x; œÉ(t)                                               (207)
                                             h       ih‚àö i
                                                1
                                                                              
                         = xi ‚àí (ti+1 ‚àí ti ) 2‚àö    t
                                                         t ‚àáx log p x; œÉ(t)                                            (208)
                         = xi + 21 (ti ‚àí ti+1 ) ‚àáx log p x; œÉ(t)
                                                                  
                                                                                                                       (209)
                         = xi + 21 œÉÃÑi2 ‚àí œÉÃÑi+1
                                            2
                                                                   
                                                    ‚àáx log p x; œÉ(t) ,                                                 (210)
   5
       https://github.com/yang-song/score_sde_pytorch
   6
       https://github.com/yang-song/score_sde_pytorch/blob/1618ddea340f3e4a2ed7852a0694a809775cf8d0/sampling.py#L191
   7
       https://github.com/yang-song/score_sde_pytorch/blob/1618ddea340f3e4a2ed7852a0694a809775cf8d0/sde_lib.py#L102
   8
       https://github.com/yang-song/score_sde_pytorch/blob/1618ddea340f3e4a2ed7852a0694a809775cf8d0/sde_lib.py#L246




                                                                34
                                                                      
which is made identical to Eq. 200 by the choice pÃÑi (x) = p x; œÉ(ti ) .
Finally, Song et al. [49] set œÉmin = 0.01 and œÉmax = 50 for CIFAR-10 (Appendix C in [49]), and
choose to represent their images in the range [0, 1] to match previous SMLD models. Since our
standardized range [‚àí1, 1] is twice as large, we must multiply œÉmin and œÉmax by 2√ó to compensate.
The ‚ÄúParameters‚Äù section of Table 1 reflects these adjusted values.

C.2.3       VE preconditioning
In the VE case, Song et al. [49] approximate the score of pt (x) of Eq. 13 directly as9
                                                                
                                   ‚àáx log pt (x) ‚âà FÃÑŒ∏ x; œÉ(t) ,                                                       (211)
                                                                                  10    11               12
where the network FÃÑŒ∏ is designed to include additional pre- and postprocessing steps:
                               FÃÑŒ∏ x; œÉ = œÉ1 FŒ∏ 2x‚àí1; log(œÉ) .
                                                               
                                                                                                                       (212)
For consistency, we handle the pre- and postprocessing using {cskip , cout , cin , cnoise } as opposed to
baking them into the network itself.
We cannot use Eqs. 211 and 212 directly in our framework, however, because they assume that the
images are represented in range [0, 1]. In order to use [‚àí1, 1] instead, we replace pt (x) ‚Üí pt (2x‚àí1),
x ‚Üí 12 x + 12 and œÉ ‚Üí 21 œÉ:
             ‚àá[ 12 x+ 21 ] log pt 2 12 x + 12 ‚àí1 ‚âà [ 11œÉ] FŒ∏ 2 12 x + 12 ‚àí1; log 12 œÉ
                                                                                 
                                                                                                  (213)
                                                         2
                                                                           
                                  2 ‚àáx log pt (x) ‚âà œÉ2 FŒ∏ x; log 12 œÉ
                                                                          
                                                                                                  (214)
                                                                           
                                  ‚àáx log p(x; œÉ) ‚âà œÉ1 FŒ∏ x; log 12 œÉ .
                                                                          
                                                                                                  (215)

We can now express the model in terms of DŒ∏ (¬∑) by replacing the left-hand side of Eq. 215 with
Eq. 3:
                                                       
               DŒ∏ x; œÉ ‚àí x /œÉ 2 = œÉ1 FŒ∏ x; log 12 œÉ
                       
                                                                                          (216)
                                                                              
                                                             1 ¬∑ x; log 12 œÉ ,
                                                                            
                         DŒ∏ x; œÉ = |{z}  1 ¬∑ x + |{z}
                                                   œÉ ¬∑ FŒ∏ |{z}                            (217)
                                                          cskip
                                                                     | {z }cout        cin
                                                                                               cnoise
where cskip , cout , cin , and cnoise match the ‚ÄúNetwork and preconditioning‚Äù section of Table 1.

C.2.4       VE training
Song et al. [49] define their training loss similarly for VP and VE, so we can reuse Eq. 185 by
borrowing the definition of score(¬∑) from Eq. 216:
                         h                                                  i
                                                                         2
                  Et,y,n s(t)œÉ(t) score s(t) (y + n); FŒ∏ , t + n/œÉ(t) 2                   (218)
                         h                                          i
                                                                 2
              = Et,y,n œÉ(t) score y + n; FŒ∏ , t + n/œÉ(t) 2                                (219)
                         h       h                                   i            i
                                                                                  2
              = Et,y,n œÉ(t) DŒ∏ y + n; œÉ(t) ‚àí (y + n) /œÉ(t)2 + n/œÉ(t) 2
                                                    
                                                                                          (220)
                         h                                  i
                             1
                                                         2
              = Et,y,n œÉ(t)    2  DŒ∏ y + n; œÉ(t) ‚àí y 2 .                                  (221)
                                                                           t
For VE training, the original implementation13 defines œÉ(t) = œÉmin œÉœÉmax
                                                                       min
                                                                              . We can thus rewrite
Eq. 221 as                                           h                           i
                                                                               2
                  Eln(œÉ)‚àºU (ln(œÉmin ),ln(œÉmax )) Ey,n œÉ12 DŒ∏ y + n; œÉ ‚àí y 2 ,
                                                                     
                                                                                              (222)
                  |           {z               }       |{z}
                                      ptrain                           Œª
which matches Eq. 108 with the choices for ptrain and Œª shown in the ‚ÄúTraining‚Äù section of Table 1.
   9
       https://github.com/yang-song/score_sde_pytorch/blob/1618ddea340f3e4a2ed7852a0694a809775cf8d0/models/utils.py#L163
  10
       https://github.com/yang-song/score_sde_pytorch/blob/1618ddea340f3e4a2ed7852a0694a809775cf8d0/models/ncsnpp.py#L239
  11
       https://github.com/yang-song/score_sde_pytorch/blob/1618ddea340f3e4a2ed7852a0694a809775cf8d0/models/ncsnpp.py#L261
  12
       https://github.com/yang-song/score_sde_pytorch/blob/1618ddea340f3e4a2ed7852a0694a809775cf8d0/models/ncsnpp.py#L379
  13
       https://github.com/yang-song/score_sde_pytorch/blob/1618ddea340f3e4a2ed7852a0694a809775cf8d0/sde_lib.py#L234




                                                                  35
C.2.5       VE practical considerations
The pre-trained VE model that we use on CIFAR-10 corresponds to the ‚ÄúNCSN++ cont. (VE)‚Äù
checkpoint14 provided by Song et al. [49]. It contains
                                                      a total of
                                                                63 million trainable parameters and
supports a continuous range of noise levels œÉ ‚àà œÉ(t ), œÉ(1) ‚âà [0.02, 100]. This is narrower than
our preferred sampling range [0.002, 80], so we set œÉmin = 0.02 in all related experiments. Note
that this limitation is lifted by our training improvements in config E, so we revert back to using
œÉmin = 0.002 with configs E and F in Table 2. When importing the model, we remove the pre- and
postprocessing steps shown in Eq. 212 to stay consistent with the definition of FŒ∏ (¬∑) in Eq. 217. With
these changes, we can run Algorithms 1 and 2 using the definitions in Table 1.
In Figure 2b, the differences between the original sampler (blue) and our reimplementation (orange)
are explained by floating point round-off errors that the original implementation suffers from at high
step counts. Our results are more accurate in these cases because we represent xi at double precision
in Algorithm 1.

C.3      Improved DDPM and DDIM

C.3.1       DDIM ODE formulation
Song et al. [47] make the observation that their deterministic DDIM sampler can be expressed as
Euler integration of the following ODE (Eq. 14 in [47]):
                                                           !
                                         (t)      x(t)
                                dx(t) = Œ∏    p               dœÉ(t),                      (223)
                                                 œÉ(t)2 + 1
where x(t) is a scaled version of the iterate that appears in their discrete update formula (Eq. 10 in
                                                                               (t)     p          
[47]) and Œ∏ is a model trained to predict the normalized noise vector, i.e., Œ∏ x(t)/ œÉ(t)2 + 1 ‚âà
n(t)/œÉ(t) for x(t)= y(t) + n(t). In our formulation, DŒ∏ is trained to approximate the clean signal,
i.e., DŒ∏ x(t); œÉ(t) ‚âà y, so we can reinterpret Œ∏ in terms of DŒ∏ as follows:
                                            n(t) = x(t) ‚àí y(t)                                                          (224)
                                                            
                                      n(t)/œÉ(t) = x(t) ‚àí y(t) /œÉ(t)                                                     (225)
                          (t)
                                     p                               
                         Œ∏     x(t)/ œÉ(t)2 + 1 = x(t) ‚àí DŒ∏ x(t); œÉ(t) /œÉ(t).                                           (226)

Assuming ideal (¬∑) and D(¬∑) in L2 sense, we can further simplify the above formula using Eq. 3:
                       p
            (t) x(t)/ œÉ(t)2 + 1 = x(t) ‚àí D x(t); œÉ(t) /œÉ(t)
                                                                 
                                                                                            (227)
                                                  h                              i
                                       = ‚àíœÉ(t) D x(t); œÉ(t) ‚àí x(t) /œÉ(t)2
                                                                   
                                                                                            (228)
                                                                         
                                       = ‚àíœÉ(t) ‚àáx(t) log p x(t); œÉ(t) .                     (229)

Substituting Eq. 229 back into Eq. 223 gives
                                                                       
                                   dx(t) = ‚àíœÉ(t) ‚àáx(t) log p x(t); œÉ(t) dœÉ(t),                                          (230)
which we can further simplify by setting œÉ(t) = t:
                                                                    
                                            dx = ‚àít ‚àáx log p x; œÉ(t) dt.                                                (231)
This matches our Eq. 4 with s(t) = 1 and œÉ(t) = t, reflected by the ‚ÄúSampling‚Äù section of Table 1.

C.3.2       iDDPM time step discretization
The original DDPM formulation of Ho et al. [16] defines the forward process (Eq. 2 in [16]) as a
Markov chain that gradually adds Gaussian noise to xÃÑ0 ‚àº pdata according to a discrete variance
schedule {Œ≤1 , . . . , Œ≤T }:
                                                      p                   
                             q(xÃÑt | xÃÑt‚àí1 ) = N xÃÑt ; 1 ‚àí Œ≤t xÃÑt‚àí1 , Œ≤t I .              (232)
  14
       ve/cifar10_ncsnpp_continuous/checkpoint_24.pth, https://drive.google.com/drive/folders/1b0gy_LLgO_DaQBgoWXwlVnL_rcAUgREh




                                                               36
The corresponding transition probability from xÃÑ0 to xÃÑt (Eq. 4 in [16]) is given by
                                                                                                t
                                           ‚àö                                                   Y
               q(xÃÑt | xÃÑ0 ) = N xÃÑt ;         Œ±ÃÑt xÃÑ0 , (1 ‚àí Œ±ÃÑt ) I ,         where   Œ±ÃÑt =         (1 ‚àí Œ≤s ).     (233)
                                                                                                s=1


Ho et al. [16] define {Œ≤t } based on a linear schedule and then calculate the corresponding {Œ±ÃÑt } from
Eq. 233. Alternatively, one can also define {Œ±ÃÑt } first and then solve for {Œ≤t }:
                                                                t
                                                                Y
                                                   Œ±ÃÑt     =              (1 ‚àí Œ≤s )                                  (234)
                                                                s=1
                                                   Œ±ÃÑt     = Œ±ÃÑt‚àí1 (1 ‚àí Œ≤t )                                         (235)
                                                                    Œ±ÃÑt
                                                   Œ≤t      = 1‚àí         .                                            (236)
                                                                  Œ±ÃÑt‚àí1

The improved DDPM formulation of Nichol and Dhariwal [37] employs a cosine schedule for Œ±ÃÑt
(Eq. 17 in [37]), defined as
                                                                     
                              f (t)                        t/T + s œÄ
                        Œ±ÃÑt =       , where f (t) = cos2          ¬∑     ,            (237)
                              f (0)                         1+s     2
where s = 0.008. In their implementation15 , however, Nichol et al. leave out the division by f (0)
and simply define16                                       
                                           2   t/T + s œÄ
                                 Œ±ÃÑt = cos             ¬∑     .                               (238)
                                                1+s      2
To prevent singularities near t = T , they also clamp Œ≤t to 0.999. We can express the clamping in
terms of Œ±ÃÑt by utilizing Eq. 233 and Eq. 234:
                                               t
                                               Y
                                Œ±ÃÑt0                     1 ‚àí [Œ≤s0 ]
                                                                      
                                       =                                                                             (239)
                                               s=1
                                               Yt                            
                                       =                 1 ‚àí min [Œ≤s ], 0.999)                                       (240)
                                               s=1
                                                t                         
                                               Y               Œ±ÃÑs
                                       =      1 ‚àí min 1 ‚àí           , 0.999                                          (241)
                                         s=1
                                                             Œ±ÃÑs‚àí1
                                          t                      
                                         Y           Œ±ÃÑs
                                       =     max         , 0.001 .                                                   (242)
                                         s=1
                                                   Œ±ÃÑs‚àí1

Let us now reinterpret the above formulas in our unified framework. Recall from Table 1 that we
denote the original iDDPM sampling steps by {uj } in the order of descending noise level œÉ(uj ),
where j ‚àà {0, . . . , M }. To harmonize the notation of Eq. 233, Eq. 238, and Eq. 239, we thus have to
replace T ‚àí‚Üí M and t ‚àí‚Üí M ‚àí j:
                                       q
           q(xÃÑj | xÃÑM ) = N xÃÑj ; Œ±ÃÑj0 xÃÑM , (1 ‚àí Œ±ÃÑj0 ) I ,
                                                              
                                                                                                (243)
                                                                
                                           2(M ‚àí j)/M + C2 œÄ
                         Œ±ÃÑj    =      cos                   ¬∑    , and                                              (244)
                                                1 + C2         2
                                          j                                        
                                         Y           Œ±ÃÑj                      Œ±ÃÑj
                         Œ±ÃÑj0   =            max                    0
                                                         , C1 = Œ±ÃÑj+1 max         , C1 ,                             (245)
                                                   Œ±ÃÑj+1                    Œ±ÃÑj+1
                                       s=M ‚àí1

where the constants are C1 = 0.001 and C2 = 0.008.
   15
        https://github.com/openai/improved-diffusion
   16
     https://github.com/openai/improved-diffusion/blob/783b6740edb79fdb7d063250db2c51cc9545dcd1/improved_diffusion/gaussian_
diffusion.py#L39




                                                                  37
We can further simplify Eq. 244:
                                                                                      
                                               (M ‚àí j)/M + C2 œÄ
                               Œ±ÃÑj    =    cos2                  ¬∑                                          (246)
                                                    1 + C2          2
                                                                  
                                               œÄ (1 + C2 ) ‚àí j/M
                                      = cos2                                                                (247)
                                               2      1 + C2
                                                                 
                                               œÄ œÄ         j
                                      = cos2     ‚àí                                                          (248)
                                               2    2 M (1 + C2 )
                                                            
                                               œÄ      j
                                      = sin2                   ,                                            (249)
                                               2 M (1 + C2 )
giving the formula shown in the ‚ÄúParameters‚Äù section of Table 1.
To harmonize the definitions of x and xÃÑ, we must match the perturbation kernel of Eq. 11 with the
transition probability of Eq. 243 for each time step t = uj :
                                                  
                                p0t x(uj ) | x(0) = q(xÃÑj | xÃÑM )                           (250)
                                                               q                     
          N x(uj ); s(t) x(0), s(uj )2 œÉ(uj )2 I = N xÃÑj ; Œ±ÃÑj0 xÃÑM , 1 ‚àí Œ±ÃÑj0 I .
                                                                                  
                                                                                            (251)

Substituting s(t) = 1 and œÉ(t) = t from Appendix C.3.1, as well as xÃÑM = x(0):
                                                   q                    
                   N x(uj ); x(0), u2j I = N xÃÑj ; Œ±ÃÑj0 x(0), 1 ‚àí Œ±ÃÑj0 I .
                                        
                                                                                                            (252)

                                                                                        q
We can match the means of these two distributions by defining xÃÑj =                      Œ±ÃÑj0 x(uj ):
                                                          q                  q    
             N x(uj ); x(0), u2j I                             Œ±ÃÑj0 x(0), 1 ‚àí Œ±ÃÑj0 I
                                                               Œ±ÃÑj0 x(uj );
                                       
                                            = N                                                             (253)
                                                              1 ‚àí Œ±ÃÑj0
                                                                        
                                            = N x(uj ); x(0),          I  .                                 (254)
                                                                Œ±ÃÑj0

Matching the variances and solving for Œ±ÃÑj0 gives

                                                   u2j    =      (1 ‚àí Œ±ÃÑj0 ) / Œ±ÃÑj0                         (255)
                                            u2j    Œ±ÃÑj0   =      1‚àí   Œ±ÃÑj0                                  (256)
                                      u2j Œ±ÃÑj0 +   Œ±ÃÑj0   =      1                                          (257)
                                     (u2j + 1)     Œ±ÃÑj0   =      1                                          (258)
                                                   Œ±ÃÑj0   =      1/   (u2j   + 1).                          (259)

Finally, we can expand the left-hand side using Eq. 245 and solve for uj‚àí1 :
                        0
                      Œ±ÃÑj+1 max(Œ±ÃÑj /Œ±ÃÑj+1 , C1 )              =     1 / (u2j + 1)                          (260)
                        Œ±ÃÑj0
                           max(Œ±ÃÑj‚àí1 /Œ±ÃÑj , C1 ) = 1 /                   (u2j‚àí1      + 1)                   (261)
                   2
                                                                         (u2j‚àí1
                        
             1 / (uj + 1) max(Œ±ÃÑj‚àí1 /Œ±ÃÑj , C1 ) = 1 /                                + 1)                   (262)
                max(Œ±ÃÑj‚àí1 /Œ±ÃÑj ,     C1 ) (u2j‚àí1 + 1)          =     u2j + 1                                (263)
                                            u2j‚àí1 + 1          =     (u2j + 1)    / max(Œ±ÃÑj‚àí1 /Œ±ÃÑj , C1 )   (264)
                                                                     s
                                                                              u2j + 1
                                                   uj‚àí1        =                               ‚àí 1,         (265)
                                                                         max(Œ±ÃÑj‚àí1 /Œ±ÃÑj , C1 )

giving a recurrence formula for {uj }, bootstrapped by uM = 0, that matches the ‚ÄúTime steps‚Äù row
of Table 1.


                                                           38
C.3.3       iDDPM preconditioning and training
We can solve DŒ∏ (¬∑) from Eq. 227 by substituting œÉ(t) = t from Appendix C.3.1:
                             p         
                        (j)                                    
                       Œ∏ x/ œÉ 2 + 1        = x ‚àí DŒ∏ (x; œÉ) /œÉ                                      (266)
                                                             p        
                                                        (j)
                                DŒ∏ (x; œÉ) = x ‚àí œÉ Œ∏ x/ œÉ 2 + 1 .                                   (267)

                                     (j)
We choose to define FŒ∏ (¬∑; j) = Œ∏ (¬∑) and solve j from œÉ by finding the nearest uj :
                                                                                
                               1 ¬∑ x ‚àí œÉ ¬∑ FŒ∏ ‚àöœÉ12 +1 ¬∑ x; arg minj |uj ‚àí œÉ| ,
                DŒ∏ (x; œÉ) = |{z}                                                                    (268)
                                      |{z}
                               cskip
                                                              |       {z       }
                                       cout
                                                 | {z }
                                                          cin             cnoise

where cskip , cout , cin , and cnoise match the ‚ÄúNetwork and preconditioning‚Äù section of Table 1.
Note that Eq. 268 is identical to the VP preconditioning formula in Eq. 181. Furthermore,
Nichol and Dhariwal [37] define their main training loss Lsimple (Eq. 14 in [37]) the same way
as Song et al. [49], with œÉ drawn uniformly from {uj }. Thus, we can reuse Eq. 190 with œÉ = uj ,
j ‚àº U(0, M ‚àí 1), and Œª(œÉ) = 1/œÉ 2 , matching the ‚ÄúTraining‚Äù section of Table 1. In addition to
Lsimple , Nichol and Dhariwal [37] also employ a secondary loss term Lvlb ; we refer the reader to
Section 3.1 in [37] for details.

C.3.4       iDDPM practical considerations
The pre-trained iDDPM model that we use on ImageNet-64 corresponds to the ‚ÄúADM (dropout)‚Äù
checkpoint17 provided by Dhariwal and Nichol [9]. It contains 296 million trainable parameters and
supports a discrete set of M = 1000 noise levels œÉ ‚àà {uj } ‚âà {20291, 642, 321, 214, 160, 128, 106,
92, 80, 71, . . . , 0.0064}. The fact that we can only evaluate FŒ∏ these specific choices of œÉ presents
three practical challenges:

          1. In the context of DDIM, we must choose how to resample {uj } to yield {ti } for N 6= M .
             Song et al. [47] employ a simple resampling scheme where ti = uk¬∑i for resampling factor
             k ‚àà Z+ . This scheme, however, requires that 1000 ‚â° 0 (mod N ), which limits the possible
             choices for N considerably. Nichol and Dhariwal [37], on the other hand, employ a more
             flexible scheme where ti = uj with j = b(M ‚àí 1)/(N ‚àí 1) ¬∑ ic. We note, however, that
             in practice the values of uj<8 are considerably larger than our preferred œÉmax = 80. We
             choose to skip these values by defining j = bj0 + (M ‚àí 1 ‚àí j0 )/(N ‚àí 1) ¬∑ ic with j0 = 8,
             matching the ‚ÄúTime steps‚Äù row in Table 1. In Figure 2c, the differences between the original
             sampler (blue) and our reimplementation (orange) are explained by this choice.
          2. In the context of our time step discretization (Eq. 5), we must ensure that œÉi ‚àà {uj }.
             We accomplish this by rounding each œÉi to its nearest supported counterpart, i.e., œÉi ‚Üê
             uarg minj |uj ‚àíœÉi | , and setting œÉmin = 0.0064 ‚âà uN ‚àí1 . This is sufficient, because Algo-
             rithm 1 only evaluates DŒ∏ (¬∑; œÉ) with œÉ ‚àà {œÉi<N }.
          3. In the context of our stochastic sampler, we must ensure that tÃÇi ‚àà {uj }. We accomplish this
             by replacing line 5 of Algorithm 2 with tÃÇi ‚Üê uarg minj |uj ‚àí(ti +Œ≥i ti )| .

With these changes, we are able to import the pre-trained model directly as FŒ∏ (¬∑) and run Algorithms 1
and 2 using the definitions in Table 1. Note that the model outputs both Œ∏ (¬∑) and Œ£Œ∏ (¬∑), as described
in Section 3.1 of [37]; we use only the former and ignore the latter.

D        Further analysis of deterministic sampling
D.1       Truncation error analysis and choice of discretization parameters

As discussed in Section 3, the fundamental reason why diffusion models tend to require a large
number of sampling steps is that any numerical ODE solver is necessarily an approximation; the
    17
         https://openaipublic.blob.core.windows.net/diffusion/jul-2021/64x64_diffusion.pt


                                                     39
kœÑ k                                            kœÑ k                                            FID
          œÅ = 1.0   1.5     2.0   3.0   7.0               œÅ = 1.0   1.5     2.0   3.0   7.0      10                CIFAR-10, VP, N = 32
102                                             102
                                                                                                  9                CIFAR-10, VE, N = 64
101                                             101                                               8                ImageNet-64, N = 12
                                                                                                  7
100                                             100
                                                                                                  6
     -1
10                                              10-1                                              5

10-2                                            10-2                                              4
     -3                                              -3
10                                              10
                                                                                                  3
10-4                                             10-4
œÉ=0.02      0.1     0.5 1    2    5 10 20     50 œÉ=0.02     0.1     0.5 1    2    5 10 20     50 œÅ=1   2   3   4   5   6   7   8    9     10

     (a) Truncation error, VE + Euler                 (b) Truncation error, VE + Heun                  (c) FID as a function of œÅ
Figure 13: (a) Local truncation error (y-axis) at different noise levels (x-axis) using Euler‚Äôs method
with the VE-based CIFAR-10 model. Each curve corresponds to a different time step discretization,
defined for N = 64 and a specific choice for the polynomial exponent œÅ. The values represent the
root mean square error (RMSE) between one Euler iteration and a sequence of multiple smaller
Euler iterations, representing the ground truth. The shaded regions, barely visible at low œÉ, represent
standard deviation over different latents x0 . (b) Corresponding error curves for Heun‚Äôs 2nd order
method (Algorithm 1). (c) FID (y-axis) as a function of the polynomial exponent (x-axis) for different
models, measured using Heun‚Äôs 2nd order method. The shaded regions indicate the range of variation
between the lowest and highest observed FID, and the dots indicate the value of œÅ that we use in all
other experiments.



larger the steps, the farther away we drift from the true solution at each step. Specifically, given
the value of xi‚àí1 at time step i ‚àí 1, the solver approximates the true x‚àói as xi , resulting in local
truncation error œÑ i = x‚àói ‚àí xi . The local errors get accumulated over the N steps, ultimately leading
to global truncation error eN .
                                                                         
Euler‚Äôs method is a first order ODE solver, meaning that œÑ i = O h2i for any sufficiently smooth
x(t), where hi = |ti ‚àí ti‚àí1 | is the local step size [50]. In other words, there exist some C and H
such that ||œÑ i || < Ch2i for every hi < H, i.e., halving hi reduces œÑ i by 4√ó. Furthermore, if we
assume that DŒ∏ is Lipschitz continuous ‚Äî which is true for all network architectures considered
in this paper ‚Äî the global truncation error is bounded by ||eN || ‚â§ E maxi ||œÑ i ||, where the value
of E depends on N , t0 , tN , and the Lipschitz constant [50]. Thus, reducing the global error for
given N , which in turn enables reducing N itself, boils down to choosing the solver and {ti } so that
maxi ||œÑ i || is minimized.
To gain insight on how the local truncation error behaves in practice, we measure the values of
œÑ i over different noise levels using the VE-based CIFAR-10 model. For a given noise level, we
set ti = œÉ ‚àí1 (œÉi ) and choose some ti‚àí1 > ti depending on the case. We then sample xi‚àí1
from p(x; œÉi‚àí1 ) and estimate the true x‚àói by performing 200 Euler steps over uniformly selected
subintervals between ti‚àí1 and t. Finally,
                                     ‚àö
                                            we plot the mean and standard deviation of the root mean
square error (RMSE), i.e., ||œÑ i ||/ dim œÑ , as a function of œÉi , averaged over 200 random samples
of xi‚àí1 . Results for Euler‚Äôs method are shown in Figure 13a, where the blue curve corresponds to
uniform step size hœÉ = 1.25 with respect to œÉ, i.e., œÉi‚àí1 = œÉi + hœÉ and ti‚àí1 = œÉ ‚àí1 (œÉi‚àí1 ). We see
that the error is very large (RMSE ‚âà 0.56) for low noise levels (œÉi ‚â§ 0.5) and considerably smaller
for high noise levels. This is in line with the common intuition that, in order to reduce eN , the step
size should be decreased monotonically with decreasing œÉ. Each curve is surrounded by a shaded
region that indicates standard deviation, barely visible at low values of œÉ. This indicates that œÑ i is
nearly constant with respect to xi‚àí1 , and thus there would be no benefit in varying {ti } schedule on
a per-sample basis.
A convenient way to vary the local step size depending on the noise level is to define {œÉi } as a
linear resampling of some monotonically increasing, unbounded warp function w(z). In other words,
œÉi<N = w(Ai + B) and œÉN = 0, where constants A and B are selected so that œÉ0 = œÉmax and
œÉN ‚àí1 = œÉmin . In practice, we set œÉmin = max(œÉlo , 0.002) and œÉmax = min(œÉhi , 80), where œÉlo and
œÉhi are the lowest and highest noise levels supported by a given model, respectively; we have found
these choices to perform reasonably well in practice. Now, to balance œÑ i between low and high
noise levels, we can, for example, use a polynomial warp function w(z) = z œÅ parameterized by the


                                                                      40
exponent œÅ. This choice leads to the following formula for {œÉi }:
                            
                                    1      i         1         1
                                                                   œÅ
                   œÉi<N = œÉmax œÅ +               œÉmin œÅ ‚àí œÉmax œÅ       , œÉN = 0,                     (269)
                                         N ‚àí1
which reduces to uniform discretization when œÅ = 1 and gives more and more emphasis to low noise
levels as œÅ increases.18
                                                             1/œÅ     œÅ
Based on the value of œÉi , we can now compute œÉi‚àí1 = œÉi ‚àí A , which enables us to visualize
œÑ i for different choices of œÅ in Figure 13a. We see that increasing œÅ reduces the error for low noise
levels (œÉ < 10) while increasing it for high noise levels (œÉ > 10). Approximate balance is achieved
at œÅ = 2, but RMSE remains relatively high (‚àº 0.03), meaning that Euler‚Äôs method drifts away from
the correct result by several ULPs at each step. While the error could be reduced by increasing N ,
we would ideally like the RMSE to be well below 0.01 even with low step counts.
Heun‚Äôs method introduces an additional correction step for xi+1 to account for the fact that dx/dt
may change between ti and ti+1 ; Euler‚Äôs method assumes it to be constant.
                                                                                The correction leads
to cubic convergence of the local truncation error, i.e., œÑ i = O h3i , at the cost of one additional
evaluation of DŒ∏ per step. We discuss the general family of Heun-like schemes later in Appendix D.2.
Figure 13b shows local truncation error for Heun‚Äôs method using the same setup as Figure 13a. We
see that the differences in ||œÑ i || are generally more pronounced, which is to be expected given the
quadratic vs. cubic convergence of the two methods. Cases where Euler‚Äôs method has low RMSE
tend to have even lower RMSE with Heun‚Äôs method, and vice versa for cases with high RMSE. Most
remarkably, the red curve shows almost constant RMSE ‚àà [0.0030, 0.0045]. This means that the
combination of Eq. 269 and Heun‚Äôs method is, in fact, very close to optimal with œÅ = 3.
Thus far, we have only considered the raw numerical error, i.e., component-wise deviation from
the true result in RGB space. The raw numerical error is relevant for certain use cases, e.g., image
manipulation where the ODE is first evaluated in the direction of increasing t and then back to t = 0
again ‚Äî in this case, ||eN || directly tells us how much the original image degrades in the process
and we can use œÅ = 3 to minimize it. Considering the generation of novel images from scratch,
however, it is reasonable to expect different noise levels to introduce different kinds of errors that
may not necessarily be on equal footing considering their perceptual importance. We investigate this
in Figure 13c, where we plot FID as a function of œÅ for different models and different choices of N .
Note that the ImageNet-64 model was only trained for a discrete set of noise levels; in order to use it
with Eq. 269, we round each ti to its nearest supported counterpart, i.e., t0i = uarg minj |uj ‚àíti | .
From the plot, we can see that even though œÅ = 3 leads to relatively good FID, it can be reduced
further by choosing œÅ > 3. This corresponds to intentionally introducing error at high noise levels
to reduce it at low noise levels, which makes intuitive sense because the value of œÉmax is somewhat
arbitrary to begin with ‚Äî increasing œÉmax can have a large impact on ||eN ||, but it does not affect the
resulting image distribution nearly as much. In general, we have found œÅ = 7 to perform reasonably
well in all cases, and use this value in all other experiments.

D.2    General family of 2nd order Runge‚ÄìKutta variants

Heun‚Äôs method illustrated in Algorithm 1 belongs to a family of explicit two-stage 2nd order Runge‚Äì
Kutta methods, each having the same computational cost. A common parameterization [50] of this
family is,
                                         h                                         i
                                                1          1
       di = f (xi ; ti ) ; xi+1 = xi + h 1 ‚àí 2Œ±      di + 2Œ± f (xi + Œ±hdi ; ti + Œ±h) ,        (270)

where h = ti+1 ‚àí ti and Œ± is a parameter that controls where the additional gradient is evaluated and
how much it influences the step taken. Setting Œ± = 1 corresponds to Heun‚Äôs method, and Œ± = 12 and
Œ± = 23 yield so-called midpoint and Ralston methods, respectively. All these variants differ in the
kind of approximation error they incur due to the geometry of the underlying function f .
To establish the optimal Œ± in our use case, we ran a separate series of experiments. According to
the results, it appears that Œ± = 1 is very close to being optimal. Nonetheless, the experimentally
  18
    In the limit, Eq. 269 reduces to the same geometric sequence employed by original VE ODE when œÅ ‚Üí ‚àû.
Thus, our discretization can be seen as a parametric generalization of the one proposed by Song et al. [49].


                                                    41
Algorithm 3 Deterministic sampling using general 2nd order Runge‚ÄìKutta, œÉ(t) = t and s(t) = 1.
 1: procedure A LPHA S AMPLER(DŒ∏ (x; œÉ), ti‚àà{0,...,N } , Œ±)
 2:    sample x0 ‚àº N 0, t20 I
 3:    for i ‚àà {0, . . . , N ‚àí 1} do
 4:        hi ‚Üê ti+1 ‚àí ti                                                                     . Step length
 5:        di ‚Üê xi ‚àí DŒ∏ (xi ; ti ) /ti                                          . Evaluate dx/dt at (x, ti )
 6:        (x0i , t0i ) ‚Üê (xi + Œ±hdi , ti + Œ±h)                                . Additional evaluation point
 7:        if t0i 6= 0 then
                 di0 ‚Üê x0i ‚àí DŒ∏ (x0i ; t0i ) /t0i                              . Evaluate dx/dt at (x0i , t0i )
                                            
 8:
                                 h                         i
 9:              xi+1 ‚Üê xi + h 1 ‚àí 2Œ±       1          1
                                                 di + 2Œ± di0             . Second order step from ti to ti+1

10:         else
11:             xi+1 ‚Üê xi + hdi                                                 . Euler step from ti to ti+1
12:     return xN



best choice was Œ± = 1.1 that performed slightly better, even though values greater than one are
theoretically hard to justify as they overshoot the target ti+1 . As we have no good explanation for
this observation and cannot tell if it holds in general, we chose not to make Œ± a new hyperparameter
and instead fixed it to 1, corresponding exactly to Heun‚Äôs method. Further analysis is left as future
work, including the possibility of having Œ± vary during sampling.
An additional benefit of setting Œ± = 1 is that it makes it possible to use pre-trained neural networks
DŒ∏ (x; œÉ) that have been trained only for specific values of œÉ. This is because a Heun step evaluates
the additional gradient at exactly ti+1 unlike the other 2nd order variants. Hence it is sufficient to
ensure that each ti corresponds to a value of œÉ that the network was trained for.
Algorithm 3 shows the pseudocode for a general 2nd order solver parameterized by Œ±. For clarity,
the pseudocode assumes the specific choices of œÉ(t) = t and s(t) = 1 that we advocate in Section 3.
Note that the fallback to Euler step (line 11) can occur only when Œ± ‚â• 1.


E     Further results with stochastic sampling

E.1   Image degradation due to excessive stochastic iteration

Figure 14 illustrates the image degradation caused by excessive Langevin iteration (Section 4,
‚ÄúPractical considerations‚Äù). These images are generated by doing a specified number of iterations at a
fixed noise level œÉ so that at each iteration an equal amount of noise is added and removed. In theory,
Langevin dynamics should bring the distribution towards the ideal distribution p(x; œÉ) but as noted
in Section 4, this holds only if the denoiser DŒ∏ (x; œÉ) induces a conservative vector field in Eq. 3.
As seen in the figure, it is clear that the image distribution suffers from repeated iteration in all cases,
although the exact failure mode depends on dataset and noise level. For low noise levels (below 0.2
or so), the images tend to oversaturate starting at 2k iterations and become fully corrupted after that.
Our heuristic of setting Stmin > 0 is designed to prevent stochastic sampling altogether at very low
noise levels to avoid this effect.
For high noise levels, we can see that iterating without the standard deviation correction, i.e., when
Snoise = 1.000, the images tend to become more abstract and devoid of color at high iteration counts;
this is especially visible in the 10k column of CIFAR-10 where the images become mostly black
and white with no discernible backgrounds. Our heuristic inflation of standard deviation by setting
Snoise > 1 counteracts this tendency efficiently, as seen in the corresponding images on the right hand
side of the figure. Notably, this still does not fix the oversaturation and corruption at low noise levels,
suggesting multiple sources for the detrimental effects of excessive iteration. Further research will be
required to better understand the root causes of these observed effects.
Figure 15 presents the output quality of our stochastic sampler in terms of FID as a function of Schurn
at fixed NFE, using pre-trained networks of Song et al. [49] and Dhariwal and Nichol [9]. Generally,
for each case and combination of our heuristic corrections, there is an optimal amount of stochasticity
after which the results start to degrade. It can also be seen that regardless of the value of Schurn , the


                                                      42
Uncond. CIFAR-10, Pre-trained, VP, Snoise = 1.000                         Uncond. CIFAR-10, Pre-trained, VP, Snoise = 1.007
                                                                   0.02


                                                                   0.05


                                                                   0.10


                                                                   0.20


                                                                   0.30


                                                                   0.40


                                                                   0.50


                                                                   0.60


                                                                   0.70


                                                                   0.80

Step 0   100         200     500   1,000    2,000   5,000 10,000    œÉ     Step 0   100         200     500   1,000    2,000   5,000 10,000

  Cond. ImageNet-64, Pre-trained, Snoise = 1.000                            Cond. ImageNet-64, Pre-trained, Snoise = 1.003

                                                                   0.05



                                                                   0.10



                                                                   0.20



                                                                   0.30



                                                                   0.40



                                                                   0.50



                                                                   0.60



                                                                   0.70

Step 0         500         1,000    2,000      5,000     10,000     œÉ     Step 0         500         1,000    2,000      5,000     10,000


Figure 14: Gradual image degradation with repeated addition and removal of noise. We start with
a random image drawn from p(x; œÉ) (first ‚àö   column) and run Algorithm 2 for a certain number of
steps (remaining columns) with fixed Œ≥i = 2 ‚àí 1. Each row corresponds to a specific choice of œÉ
(indicated in the middle) that we keep fixed throughout the entire process. We visualize the results
after running them through the denoiser, i.e., DŒ∏ (xi ; œÉ).




                                                                   43
 FID                                         FID                                     FID
            Deterministic
  5.0                                        4.0                                      2.8
            Stmin,tmax + Snoise = 1
  4.5       Stmin,tmax = [0, ‚àû]                                                      2.6
            Snoise = 1                       3.5
            Optimal settings                                                         2.4
  4.0
                                                                                     2.2
  3.5                                        3.0
                                                                                     2.0
  3.0                                                                                1.8
                                             2.5
  2.5                                                                                1.6

   2.0                                   2.0                                         1.4
Schurn =0 10 20 30 40 50 60 70 80 90 100     0      10 20 30 40 50 60 70 80 90 100          0    10 20 30 40 50 60 70 80 90 100

         (a) Uncond. CIFAR-10, VP                  (b) Uncond. CIFAR-10, VE                     (c) Class-cond. ImageNet-64
Figure 15: Ablations of our stochastic sampler (Algorithm 2) parameters using pre-trained networks
of Song et al. [49] and Dhariwal and Nichol [9]. Each curve shows FID (y-axis) as a function of
Schurn (x-axis) for N = 256 steps (NFE = 511). The dashed red lines correspond to our deterministic
sampler (Algorithm 1), equivalent to setting Schurn = 0. The purple curves correspond to optimal
choices for {Stmin , Stmax , Snoise }, found separately for each case using grid search. Orange, blue, and
green correspond to disabling the effects of Stmin,tmax and/or Snoise . The shaded regions indicate the
range of variation between the lowest and highest observed FID.


                  Table 5: Parameters used for the stochastic sampling experiments in Section 4.
                               CIFAR-10                ImageNet
    Parameter                                                                                       Grid search
                             VP       VE      Pre-trained   Our model
         Schurn               30       80         80             40          0, 10, 20, 30, . . . , 70, 80, 90, 100
         Stmin               0.01     0.05       0.05           0.05         0, 0.005, 0.01, 0.02, . . . , 1, 2, 5, 10
         Stmax                1        1          50             50          0.2, 0.5, 1, 2, . . . , 10, 20, 50, 80
         Snoise             1.007    1.007      1.003          1.003         1.000, 1.001, . . . , 1.009, 1.010



best results are obtained by enabling all corrections, although whether Snoise or Stmin,tmax is more
important depends on the case.


E.2        Stochastic sampling parameters

Table 5 lists the values for Schurn , Stmin , Stmax , and Snoise that we used in our stochastic sampling
experiments. These were determined with a grid search over the combinations listed in the rightmost
column. It can be seen that the optimal parameters depend on the case; better understanding of the
degradation phenomena will hopefully give rise to more direct ways of handling the problem in the
future.


F        Implementation details

We implemented our techniques in a newly written codebase, based loosely on the original imple-
mentations by Song et al.19 [49], Dhariwal and Nichol20 [9], and Karras et al.21 [26]. We performed
extensive testing to verify that our implementation produced exactly the same results as previous
work, including samplers, pre-trained models, network architectures, training configurations, and
evaluation. We ran all experiments using PyTorch 1.10.0, CUDA 11.4, and CuDNN 8.2.0 on NVIDIA
DGX-1‚Äôs with 8 Tesla V100 GPUs each.
Our implementation and pre-trained models are available at https://github.com/NVlabs/edm


    19
       https://github.com/yang-song/score_sde_pytorch
    20
       https://github.com/openai/guided-diffusion
    21
       https://github.com/NVlabs/stylegan3


                                                              44
Table 6: Our augmentation pipeline. Each training image undergoes a combined geometric transfor-
mation based on 8 random parameters that receive non-zero values with a certain probability. The
model is conditioned with an additional 9-dimensional input vector derived from these parameters.
  Augmentation          Transformation                     Parameters          Prob.     Conditioning       Constants
                                             
  x-flip                S CALE 2D 1 ‚àí 2a0 , 1              a0 ‚àº U{0, 1}        100%      a0                 Aprob = 12%
                                             
  y-flip                S CALE 2D 1, 1 ‚àí 2a1               a1 ‚àº U{0, 1}        Aprob     a1                        or 15%
                                             a2
  Scaling               S CALE 2D(Ascale ) ,               a2 ‚àº N (0, 1)       Aprob     a2                 Ascale = 20.2
                                 (Ascale )a2
                                             
                                       
  Rotation              ROTATE 2D ‚àía3                      a3 ‚àº U (‚àíœÄ, œÄ)      Aprob     cos a3 ‚àí 1
                                                                                         sin a3
                                                                                                            Aaniso = 20.2
                                         
  Anisotropy            ROTATE 2D   a4                     a4 ‚àº U (‚àíœÄ, œÄ)      Aprob     a5 cos a4
                                             a5
                        S CALE 2D   (Aaniso ) ,            a5 ‚àº N (0, 1)                 a5 sin a4
                                                  a5
                                                       
                                 1/(Aaniso )
                                      
                        ROTATE 2D ‚àía4

  Translation           T RANSLATE 2D    (Atrans )a6 ,     a6 ‚àº N (0, 1)       Aprob     a6                 Atrans = 1/8
                                                     
                                         (Atrans )a7       a7 ‚àº N (0, 1)                 a7



F.1     FID calculation

We calculate FID [15] between 50,000 generated images and all available real images, without any aug-
mentation such as x-flips. We use the pre-trained Inception-v3 model provided with StyleGAN322 [26]
that is, in turn, a direct PyTorch translation of the original TensorFlow-based model23 . We have
verified that our FID implementation produces identical results compared to Dhariwal and Nichol [9]
and Karras et al. [26]. To reduce the impact of random variation, typically in the order of ¬±2%,
we compute FID three times in each experiment and report the minimum. We also highlight the
difference between the highest and lowest achieved FID in Figures 4, 5b, 13c, and 15.

F.2     Augmentation regularization

In Section 5, we propose to combat overfitting of DŒ∏ using conditional augmentation. We build our
augmentation pipeline around the same concepts that were originally proposed by Karras et al. [25]
in the context of GANs. In practice, we employ a set of 6 geometric transformations; we have found
other types of augmentations, such as color corruption and image-space filtering, to be consistently
harmful for diffusion-based models.
The details of our augmentation pipeline are shown in Table 6. We apply the augmentations indepen-
dently to each training image y ‚àº pdata prior to adding the noise n ‚àº N (0, œÉ 2 I). First, we determine
whether to enable or disable each augmentation based on a weighted coin toss. The probability of
enabling a given augmentation (‚ÄúProb.‚Äù column) is fixed to 12% for CIFAR-10 and 15% for FFHQ
and AFHQv2, except for x-flips that are always enabled. We then draw 8 random parameters from
their corresponding distributions (‚ÄúParameters‚Äù column); if a given augmentation is disabled, we
override the associated parameters with zero. Based on these, we construct a homogeneous 2D
transformation matrix based on the parameters (‚ÄúTransformation‚Äù column). This transformation is
applied to the image using the implementation of [25] that employs 2√ó supersampled high-quality
Wavelet filters. Finally, we construct a 9-dimensional conditioning input vector (‚ÄúConditioning‚Äù
column) and feed it to the denoiser network, in addition to the image and noise level inputs.
The role of the conditioning input is to present the network with a set of auxiliary tasks; in addition
to the main task of modeling p(x; œÉ), we effectively ask the network to also model an infinite
set of distributions p(x; œÉ, a) for each possible choice of the augmentation parameters a. These
auxiliary tasks provide the network with a large variety of unique training samples, preventing it from
  22
       https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/metrics/inception-2015-12-05.pkl
  23
       http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz




                                                               45
                  Table 7: Hyperparameters used for the training runs in Section 5.
                                      CIFAR-10                    FFHQ & AFHQv2               ImagetNet
 Hyperparameter
                               Baseline          Ours          Baseline          Ours            Ours
 Number of GPUs                   4               8               4               8               32
 Duration (Mimg)                 200             200             200             200             2500
 Minibatch size                  128             512             128             256             4096
 Gradient clipping                X               ‚Äì               X               ‚Äì               ‚Äì
 Mixed-precision (FP16)           ‚Äì               ‚Äì               ‚Äì               ‚Äì               X
 Learning rate √ó104               2              10                2              2                1
 LR ramp-up (Mimg)               0.64            10              0.64            10               10
 EMA half-life (Mimg)         0.89 / 0.9         0.5          0.89 / 0.9         0.5              50
                              (VP / VE)                       (VP / VE)
 Dropout probability            10%              13%            10%           5% / 25%           10%
                                                                            (FFHQ / AFHQ)
 Channel multiplier              128              128            128             128             192
 Channels per resolution       1-2-2-2           2-2-2        1-1-2-2-2        1-2-2-2         1-2-3-4
 Dataset x-flips                  X                ‚Äì              X               ‚Äì               ‚Äì
 Augment probability              ‚Äì              12%              ‚Äì             15%               ‚Äì



overfitting to any individual sample. Still, the auxiliary tasks appear to be beneficial for the main
task; we speculate that this is because the denoising operation itself is similar for every choice of a.
We have designed the conditioning input so that zero corresponds to the case where no augmentations
were applied. During sampling, we simply set a = 0 to obtain results consistent with the main
task. We have not observed any leakage between the auxiliary tasks and the main task; the generated
images exhibit no traces of out-of-domain geometric transformations even with Aprob = 100%. In
practice, this means that we are free to choose the constants {Aprob , Ascale , Aaniso , Atrans } any way we
like as long as the results improve. Horizontal flips serve as an interesting example. Most of the prior
work augments the training set with random x-flips, which is beneficial for most datasets but has the
downside that any text or logos may appear mirrored in the generated images. With our non-leaky
augmentations, we get the same benefits without the downsides by executing the x-flip augmentation
with 100% probability. Thus, we rely exclusively on our augmentation scheme and disable dataset
x-flips to ensure that the generated images stay true to the original distribution.

F.3   Training configurations

Table 7 shows the exact set of hyperparameters that we used in our training experiments reported in
Section 5. We will first detail the configurations used with CIFAR-10, FFHQ, and AFHQv2, and then
discuss the training of our improved ImageNet model.
Config A of Table 2 (‚ÄúBaseline‚Äù) corresponds to the original setup of Song et al. [49] for the two
cases (VP and VE), and config F (‚ÄúOurs‚Äù) corresponds to our improved setup. We trained each
model until a total of 200 million images had been drawn from the training set, abbreviated as ‚Äú200
Mimg‚Äù in Table 7; this corresponds to a total of ‚àº400,000 training iterations using a batch size of
512. We saved a snapshot of the model every 2.5 million images and reported results for the snapshot
that achieved the lowest FID according to our deterministic sampler with NFE = 35 or NFE = 79,
depending on the resolution.
In config B, we re-adjust the basic hyperparameters to enable faster training and obtain a more
meaningful point of comparison. Specifically, we increase the parallelism from 4 to 8 GPUs and
batch size from 128 to 512 or 256, depending on the resolution. We also disable gradient clipping,
i.e., forcing kdL(DŒ∏ )/dŒ∏k2 ‚â§ 1, that we found to provide no benefit in practice. Furthermore, we
increase the learning rate from 0.0002 to 0.001 for CIFAR-10, ramping it up during the first 10
million images, and standardize the half-life of the exponential moving average of Œ∏ to 0.5 million
images. Finally, we adjust the dropout probability for each dataset as shown in Table 7 via a full grid
search at 1% increments. Our total training time is approximately 2 days for CIFAR-10 at 32√ó32
resolution and 4 days for FFHQ and AFHQv2 at 64√ó64 resolution.


                                                     46
                  Table 8: Details of the network architectures used in this paper.
                                              DDPM++           NCSN++            ADM
           Parameter
                                                (VP)             (VE)          (ImageNet)
           Resampling filter                    Box            Bilinear           Box
           Noise embedding                   Positional        Fourier          Positional
           Skip connections in encoder           ‚Äì             Residual             ‚Äì
           Skip connections in decoder           ‚Äì                ‚Äì                 ‚Äì
           Residual blocks per resolution        4                4                 3
           Attention resolutions               {16}             {16}           {32, 16, 8}
           Attention heads                       1                1              6-9-12
           Attention blocks in encoder           4                4                 9
           Attention blocks in decoder           2                2                13



In config C, we improve the expressive power of the model by removing the 4√ó4 layers and
doubling the capacity of the 16√ó16 layers instead; we found the former to mainly contribute to
overfitting, whereas the latter were critical for obtaining high-quality results. The original models of
Song et al. [49] employ 128 channels at 64√ó64 (where applicable) and 32√ó32, and 256 channels
at 16√ó16, 8√ó8, and 4√ó4. We change these numbers to 128 channels at 64√ó64 (where applicable),
and 256 channels at 32√ó32, 16√ó16, and 8√ó8. We abbreviate these counts in Table 7 as multiples
of 128, listed from the highest resolution to the lowest. In practice, this rebalancing reduces the
total number of trainable parameters slightly, resulting in ‚àº56 million parameters for each model at
32√ó32 resolution and ‚àº62 million parameters at 64√ó64 resolution.
In config D, we replace the original preconditioning with our improved formulas (‚ÄúNetwork and
preconditioning‚Äù section in Table 1). In config E, we do the same for the noise distribution and loss
weighting (‚ÄúTraining‚Äù section in Table 1). Finally, in config F, we enable augmentation regularization
as discussed in Appendix F.2. The other hyperparameters remain the same as in config C.
With ImageNet-64, it is necessary to train considerably longer compared to the other datasets in order
to reach state-of-the-art results. To reduce the training time, we employed 32 NVIDIA Ampere GPUs
(4 nodes) with a batch size of 4096 (128 per GPU) and utilized the high-performance Tensor Cores
via mixed-precision FP16/FP32 training. In practice, we store the trainable parameters as FP32 but
cast them to FP16 when evaluating FŒ∏ , except for the embedding and self-attention layers, where
we found the limited exponent range of FP16 to occasionally lead to stability issues. We trained
the model for two weeks, corresponding to ‚àº2500 million images drawn from the training set and
‚àº600,000 training iterations, using learning rate 0.0001, exponential moving average of 50 million
images, and the same model architecture and dropout probability as Dhariwal and Nichol [9]. We did
not find overfitting to be a concern, and thus chose to not employ augmentation regularization.


F.4   Network architectures

As a result of our training improvements, the VP and VE cases become otherwise identical in con-
fig F except for the network architecture; VP employs the DDPM++ architecture while VE employs
NCSN++, both of which were originally proposed by Song et al. [49]. These architectures corre-
spond to relatively straightforward variations of the same U-net backbone with three differences, as
illustrated in Table 8. First, DDPM++ employs box filter [1, 1] for the upsampling and downsampling
layers whereas NCSN++ employs bilinear filter [1, 3, 3, 1]. Second, DDPM++ inherits its positional
encoding scheme for the noise level directly from DDPM [16] whereas NCSN++ replaces it with
random Fourier features [52]. Third, NCSN++ incorporates additional residual skip connections
from the input image to each block in the encoder, as explained in Appendix H of [49] (‚Äúprogressive
growing architectures‚Äù).
For class conditioning and augmentation regularization, we extend the original DDPM++ and
NCSN++ arhictectures by introducing two optional conditioning inputs alongside‚àöthe noise level
input. We represent class labels as one-hot encoded vectors that we first scale by C, where C is
the total number of classes, and then feed through a fully-connected layer. For the augmentation
parameters, we feed the conditioning inputs of Appendix F.2 through a fully-connected layer as-is.


                                                  47
We then combine the resulting feature vectors with the original noise level conditioning vector through
elementwise addition.
For class-conditional ImageNet-64, we use the ADM architecture of Dhariwal and Nichol [9] with
no changes. The model has a total of ‚àº296 million trainable parameters. As detailed in Tables 7
and 8, the most notable differences to DDPM++ include the use of a slightly shallower model (3
residual blocks per resolution instead of 4) with considerably more channels (e.g., 768 in the lowest
resolution instead of 256), more self-attention layers interspersed throughout the network (22 instead
of 6), and the use of multi-head attention (e.g., 12 heads in the lowest resolution). We feel that the
precise impact of architectural choices remains an interesting question for future work.

F.5   Licenses

Datasets:

       ‚Ä¢   CIFAR-10 [29]:   MIT license
       ‚Ä¢   FFHQ [27]:       Creative Commons BY-NC-SA 4.0 license
       ‚Ä¢   AFHQv2 [7]:      Creative Commons BY-NC 4.0 license
       ‚Ä¢   ImageNet [8]:    The license status is unclear

Pre-trained models:

       ‚Ä¢ CIFAR-10 models by Song et al. [49]:                  Apache V2.0 license
       ‚Ä¢ ImageNet-64 model by Dhariwal and Nichol [9]:         MIT license
       ‚Ä¢ Inception-v3 model by Szegedy et al. [51]:            Apache V2.0 license




                                                  48
